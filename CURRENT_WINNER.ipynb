{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from datetime import timedelta\n",
    "\n",
    "receivals = pd.read_csv('./Project_materials/data/kernel/receivals.csv')\n",
    "purchase_orders = pd.read_csv('./Project_materials/data/kernel/purchase_orders.csv')\n",
    "prediction_mapping = pd.read_csv('./Project_materials/data/prediction_mapping.csv')\n",
    "sample_submission = pd.read_csv('./Project_materials/data/sample_submission.csv')\n",
    "\n",
    "# Convert dates\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "purchase_orders['delivery_date'] = pd.to_datetime(purchase_orders['delivery_date'], utc=True).dt.tz_localize(None)\n",
    "purchase_orders['created_date_time'] = pd.to_datetime(purchase_orders['created_date_time'], utc=True).dt.tz_localize(None)\n",
    "prediction_mapping['forecast_start_date'] = pd.to_datetime(prediction_mapping['forecast_start_date'])\n",
    "prediction_mapping['forecast_end_date'] = pd.to_datetime(prediction_mapping['forecast_end_date'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LightGBM STEP 5: REMOVE CALIBRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# DATA CLEANING\n",
    "# ============================================================================\n",
    "print(\"\\n[1] DATA CLEANING\")\n",
    "receivals = receivals[receivals['net_weight'] > 0]\n",
    "receivals = receivals[receivals['rm_id'].notna()]\n",
    "receivals = receivals.sort_values('date_arrival')\n",
    "print(f\"Clean receivals: {len(receivals)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING DATA GENERATION (STEP 1 FEATURES)\n",
    "# ============================================================================\n",
    "print(\"\\n[2] CREATING TRAINING DATA WITH STEP 1 FEATURES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "train_dates = pd.date_range(start='2024-01-01', end='2024-11-30', freq='MS')\n",
    "forecast_horizons = [7, 30, 60, 90, 150]\n",
    "\n",
    "print(f\"Using {len(train_dates)} training dates x {len(forecast_horizons)} horizons\")\n",
    "\n",
    "training_data = []\n",
    "active_rm_ids = receivals[receivals['date_arrival'] >= '2024-01-01']['rm_id'].unique()\n",
    "print(f\"Active rm_ids in 2024: {len(active_rm_ids)}\")\n",
    "\n",
    "for i, train_date in enumerate(train_dates):\n",
    "    print(f\"Processing date {i+1}/{len(train_dates)}: {train_date.date()}...\")\n",
    "    \n",
    "    for rm_id in active_rm_ids:\n",
    "        hist = receivals[\n",
    "            (receivals['rm_id'] == rm_id) &\n",
    "            (receivals['date_arrival'] < train_date)\n",
    "        ]\n",
    "        \n",
    "        if len(hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        cutoff_365 = train_date - timedelta(days=365)\n",
    "        cutoff_180 = train_date - timedelta(days=180)\n",
    "        cutoff_90 = train_date - timedelta(days=90)\n",
    "        cutoff_30 = train_date - timedelta(days=30)\n",
    "        \n",
    "        recent_365 = hist[hist['date_arrival'] >= cutoff_365]\n",
    "        recent_180 = hist[hist['date_arrival'] >= cutoff_180]\n",
    "        recent_90 = hist[hist['date_arrival'] >= cutoff_90]\n",
    "        recent_30 = hist[hist['date_arrival'] >= cutoff_30]\n",
    "        \n",
    "        # Basic aggregations\n",
    "        if len(recent_365) > 0:\n",
    "            total_365 = recent_365['net_weight'].sum()\n",
    "            count_365 = len(recent_365)\n",
    "            days_since = (train_date - recent_365['date_arrival'].max()).days\n",
    "        else:\n",
    "            total_365 = count_365 = days_since = 0\n",
    "        \n",
    "        if len(recent_180) > 0:\n",
    "            total_180 = recent_180['net_weight'].sum()\n",
    "            count_180 = len(recent_180)\n",
    "        else:\n",
    "            total_180 = count_180 = 0\n",
    "        \n",
    "        if len(recent_90) > 0:\n",
    "            total_90 = recent_90['net_weight'].sum()\n",
    "            count_90 = len(recent_90)\n",
    "        else:\n",
    "            total_90 = count_90 = 0\n",
    "        \n",
    "        if len(recent_30) > 0:\n",
    "            total_30 = recent_30['net_weight'].sum()\n",
    "            count_30 = len(recent_30)\n",
    "            rate_30 = total_30 / 30\n",
    "        else:\n",
    "            total_30 = count_30 = rate_30 = 0\n",
    "        \n",
    "        # Rates\n",
    "        rate_90 = total_90 / 90 if total_90 > 0 else 0\n",
    "        \n",
    "        # Recency-weighted sum\n",
    "        if len(recent_90) > 0:\n",
    "            days_ago = (train_date - recent_90['date_arrival']).dt.days\n",
    "            weights = 1.0 / (days_ago + 1)\n",
    "            recency_weighted = (recent_90['net_weight'] * weights).sum()\n",
    "        else:\n",
    "            recency_weighted = 0\n",
    "        \n",
    "        # Active days ratio\n",
    "        if len(recent_90) > 0:\n",
    "            active_days_90 = recent_90['date_arrival'].dt.date.nunique()\n",
    "            active_ratio_90 = active_days_90 / 90\n",
    "        else:\n",
    "            active_ratio_90 = 0\n",
    "        \n",
    "        for horizon in forecast_horizons:\n",
    "            forecast_end = train_date + timedelta(days=horizon)\n",
    "            \n",
    "            actual = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] >= train_date) &\n",
    "                (receivals['date_arrival'] <= forecast_end)\n",
    "            ]\n",
    "            target = actual['net_weight'].sum()\n",
    "            \n",
    "            training_data.append({\n",
    "                'rm_id': rm_id,\n",
    "                'train_date': train_date,\n",
    "                'forecast_horizon': horizon,\n",
    "                'total_weight_365d': total_365,\n",
    "                'count_365d': count_365,\n",
    "                'days_since_last': days_since,\n",
    "                'total_weight_90d': total_90,\n",
    "                'count_90d': count_90,\n",
    "                'rate_90': rate_90,\n",
    "                'total_weight_180d': total_180,\n",
    "                'count_180d': count_180,\n",
    "                'total_30': total_30,\n",
    "                'count_30': count_30,\n",
    "                'rate_30': rate_30,\n",
    "                'recency_weighted': recency_weighted,\n",
    "                'active_ratio_90': active_ratio_90,\n",
    "                'target': target\n",
    "            })\n",
    "\n",
    "print(f\"\\nGenerated {len(training_data)} training samples\")\n",
    "train_df = pd.DataFrame(training_data)\n",
    "\n",
    "print(f\"Samples with target > 0: {(train_df['target'] > 0).sum()} ({(train_df['target'] > 0).sum() / len(train_df) * 100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# TIME-BASED TRAIN/VAL SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\n[3] TIME-BASED TRAIN/VAL SPLIT\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "split_date = pd.to_datetime('2024-09-01')\n",
    "\n",
    "train_mask = train_df['train_date'] < split_date\n",
    "val_mask = train_df['train_date'] >= split_date\n",
    "\n",
    "feature_cols = [c for c in train_df.columns if c not in ['target', 'train_date']]\n",
    "\n",
    "X_train = train_df[train_mask][feature_cols]\n",
    "y_train = train_df[train_mask]['target']\n",
    "X_val = train_df[val_mask][feature_cols]\n",
    "y_val = train_df[val_mask]['target']\n",
    "\n",
    "print(f\"Training samples (before {split_date.date()}): {len(X_train)}\")\n",
    "print(f\"Validation samples (>= {split_date.date()}): {len(X_val)}\")\n",
    "\n",
    "train_mean = y_train.mean()\n",
    "val_mean = y_val.mean()\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Training mean: {train_mean:,.0f} kg\")\n",
    "print(f\"  Validation mean: {val_mean:,.0f} kg\")\n",
    "print(f\"  Difference: {((val_mean - train_mean) / train_mean * 100):+.1f}%\")\n",
    "\n",
    "print(f\"\\nNumber of features: {len(feature_cols)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN LightGBM MODELS (TWO-STAGE WITH ALPHA=0.10)\n",
    "# ============================================================================\n",
    "print(\"\\n[4] TRAINING LightGBM MODELS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "# Classifier\n",
    "y_train_bin = (y_train > 0).astype(int)\n",
    "y_val_bin = (y_val > 0).astype(int)\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "print(\"Training LightGBM Classifier...\")\n",
    "clf.fit(\n",
    "    X_train, y_train_bin,\n",
    "    eval_set=[(X_val, y_val_bin)],\n",
    "    callbacks=[lgb.log_evaluation(period=100)]\n",
    ")\n",
    "\n",
    "# Regressor with alpha=0.10\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='quantile',\n",
    "    alpha=0.10,\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(f\"Training LightGBM Regressor (quantile={model.alpha})...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.log_evaluation(period=100)]\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# NO CALIBRATION (REMOVED!)\n",
    "# ============================================================================\n",
    "print(\"\\n[4c] CALIBRATION: REMOVED\")\n",
    "print(\"-\"*80)\n",
    "print(\"⚠️  Skipping per-horizon calibration entirely\")\n",
    "print(\"   Let the model's forecast_horizon feature handle horizon effects naturally\")\n",
    "print(\"   Hypothesis: Sep-Nov calibration doesn't generalize to 2025\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n[5] MAKING PREDICTIONS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "forecast_start = pd.to_datetime('2025-01-01')\n",
    "\n",
    "# Pre-compute features for all rm_ids\n",
    "rm_features = {}\n",
    "\n",
    "for rm_id in prediction_mapping['rm_id'].unique():\n",
    "    hist = receivals[\n",
    "        (receivals['rm_id'] == rm_id) &\n",
    "        (receivals['date_arrival'] < forecast_start)\n",
    "    ]\n",
    "    \n",
    "    if len(hist) == 0:\n",
    "        rm_features[rm_id] = {\n",
    "            'total_weight_365d': 0,\n",
    "            'count_365d': 0,\n",
    "            'days_since_last': 999,\n",
    "            'total_weight_90d': 0,\n",
    "            'count_90d': 0,\n",
    "            'rate_90': 0,\n",
    "            'total_weight_180d': 0,\n",
    "            'count_180d': 0,\n",
    "            'total_30': 0,\n",
    "            'count_30': 0,\n",
    "            'rate_30': 0,\n",
    "            'recency_weighted': 0,\n",
    "            'active_ratio_90': 0\n",
    "        }\n",
    "        continue\n",
    "    \n",
    "    cutoff_365 = forecast_start - timedelta(days=365)\n",
    "    cutoff_180 = forecast_start - timedelta(days=180)\n",
    "    cutoff_90 = forecast_start - timedelta(days=90)\n",
    "    cutoff_30 = forecast_start - timedelta(days=30)\n",
    "    \n",
    "    recent_365 = hist[hist['date_arrival'] >= cutoff_365]\n",
    "    recent_180 = hist[hist['date_arrival'] >= cutoff_180]\n",
    "    recent_90 = hist[hist['date_arrival'] >= cutoff_90]\n",
    "    recent_30 = hist[hist['date_arrival'] >= cutoff_30]\n",
    "    \n",
    "    if len(recent_365) > 0:\n",
    "        total_365 = recent_365['net_weight'].sum()\n",
    "        count_365 = len(recent_365)\n",
    "        days_since = (forecast_start - recent_365['date_arrival'].max()).days\n",
    "    else:\n",
    "        total_365 = count_365 = days_since = 0\n",
    "    \n",
    "    if len(recent_180) > 0:\n",
    "        total_180 = recent_180['net_weight'].sum()\n",
    "        count_180 = len(recent_180)\n",
    "    else:\n",
    "        total_180 = count_180 = 0\n",
    "    \n",
    "    if len(recent_90) > 0:\n",
    "        total_90 = recent_90['net_weight'].sum()\n",
    "        count_90 = len(recent_90)\n",
    "        rate_90 = total_90 / 90\n",
    "    else:\n",
    "        total_90 = count_90 = rate_90 = 0\n",
    "    \n",
    "    if len(recent_30) > 0:\n",
    "        total_30 = recent_30['net_weight'].sum()\n",
    "        count_30 = len(recent_30)\n",
    "        rate_30 = total_30 / 30\n",
    "    else:\n",
    "        total_30 = count_30 = rate_30 = 0\n",
    "    \n",
    "    # Recency-weighted\n",
    "    if len(recent_90) > 0:\n",
    "        days_ago = (forecast_start - recent_90['date_arrival']).dt.days\n",
    "        weights = 1.0 / (days_ago + 1)\n",
    "        recency_weighted = (recent_90['net_weight'] * weights).sum()\n",
    "    else:\n",
    "        recency_weighted = 0\n",
    "    \n",
    "    # Active ratio\n",
    "    if len(recent_90) > 0:\n",
    "        active_days_90 = recent_90['date_arrival'].dt.date.nunique()\n",
    "        active_ratio_90 = active_days_90 / 90\n",
    "    else:\n",
    "        active_ratio_90 = 0\n",
    "    \n",
    "    rm_features[rm_id] = {\n",
    "        'total_weight_365d': total_365,\n",
    "        'count_365d': count_365,\n",
    "        'days_since_last': days_since,\n",
    "        'total_weight_90d': total_90,\n",
    "        'count_90d': count_90,\n",
    "        'rate_90': rate_90,\n",
    "        'total_weight_180d': total_180,\n",
    "        'count_180d': count_180,\n",
    "        'total_30': total_30,\n",
    "        'count_30': count_30,\n",
    "        'rate_30': rate_30,\n",
    "        'recency_weighted': recency_weighted,\n",
    "        'active_ratio_90': active_ratio_90\n",
    "    }\n",
    "\n",
    "print(f\"Pre-computed features for {len(rm_features)} rm_ids\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "\n",
    "for idx, row in prediction_mapping.iterrows():\n",
    "    rm_id = row['rm_id']\n",
    "    forecast_end = row['forecast_end_date']\n",
    "    horizon = (forecast_end - forecast_start).days + 1\n",
    "    \n",
    "    feat = rm_features[rm_id]\n",
    "    \n",
    "    feature_dict = {\n",
    "        'rm_id': rm_id,\n",
    "        'forecast_horizon': horizon,\n",
    "        'total_weight_365d': feat['total_weight_365d'],\n",
    "        'count_365d': feat['count_365d'],\n",
    "        'days_since_last': feat['days_since_last'],\n",
    "        'total_weight_90d': feat['total_weight_90d'],\n",
    "        'count_90d': feat['count_90d'],\n",
    "        'rate_90': feat['rate_90'],\n",
    "        'total_weight_180d': feat['total_weight_180d'],\n",
    "        'count_180d': feat['count_180d'],\n",
    "        'total_30': feat['total_30'],\n",
    "        'count_30': feat['count_30'],\n",
    "        'rate_30': feat['rate_30'],\n",
    "        'recency_weighted': feat['recency_weighted'],\n",
    "        'active_ratio_90': feat['active_ratio_90']\n",
    "    }\n",
    "    \n",
    "    feature_vector = pd.DataFrame([feature_dict])[feature_cols]\n",
    "    \n",
    "    # Two-stage prediction\n",
    "    reg_pred = max(0, model.predict(feature_vector)[0])\n",
    "    prob_pos = clf.predict_proba(feature_vector)[:, 1][0]\n",
    "    pred = reg_pred * prob_pos\n",
    "    \n",
    "    # Guardrails\n",
    "    days_inactive = feat['days_since_last']\n",
    "    total_365 = feat['total_weight_365d']\n",
    "    cap_upper = (total_365 / 365.0) * horizon * 1.5\n",
    "    \n",
    "    if days_inactive > 365:\n",
    "        pred = 0.0\n",
    "    elif 180 < days_inactive <= 365:\n",
    "        cold_cap = 0.08 * total_365\n",
    "        pred = min(pred, cold_cap)\n",
    "    \n",
    "    pred = max(0.0, min(pred, cap_upper))\n",
    "    \n",
    "    predictions.append({'ID': row['ID'], 'predicted_weight': pred})\n",
    "    \n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(prediction_mapping)}...\")\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "print(\"\\n[6] PREDICTION STATISTICS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Predictions mean: {predictions_df['predicted_weight'].mean():,.0f} kg\")\n",
    "print(\"\\nPrediction statistics:\")\n",
    "print(predictions_df['predicted_weight'].describe())\n",
    "print(f\"Predictions > 0: {(predictions_df['predicted_weight'] > 0).sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE SUBMISSION\n",
    "# ============================================================================\n",
    "print(\"\\n[7] CREATING SUBMISSION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "submission = sample_submission.copy()\n",
    "submission['predicted_weight'] = predictions_df['predicted_weight'].values\n",
    "submission.to_csv('lightgbm_step5_no_calibration.csv', index=False)\n",
    "print(\"Saved to 'lightgbm_step5_no_calibration.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE - STEP 5: NO CALIBRATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nChanges from Step 4 (6,140):\")\n",
    "print(\"  ✅ Kept all Step 1 features and two-stage model\")\n",
    "print(\"  ✅ Kept alpha=0.10 from Step 4\")\n",
    "print(\"  ✅ Kept original guardrails from Step 1\")\n",
    "print(\"  ❌ REMOVED: Per-horizon calibration entirely\")\n",
    "print(\"  ✅ Hypothesis: Calibration overfits to Sep-Nov 2024, hurts 2025 generalization\")\n",
    "print(\"  ✅ Let forecast_horizon feature handle horizon effects naturally\")\n",
    "print(\"  ✅ Expected: Unknown direction, but could improve if calibration was harmful\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
