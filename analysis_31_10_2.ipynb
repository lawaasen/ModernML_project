{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fbbfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CRITICAL ISSUE ANALYSIS: LEAKAGE & PATTERN VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "[1] LOADING DATA\n",
      "Total receivals: 122383\n",
      "\n",
      "[2] RECREATING TRAINING DATA\n",
      "Total training samples: 2725\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS 1: CUMULATIVE PATTERN CHECK\n",
      "================================================================================\n",
      "NOTE: Targets SHOULD be cumulative by design - this is expected!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total samples checked: 220\n",
      "Percentage of cumulative patterns: 100.0%\n",
      "Percentage with deliveries in ALL horizons: 23.2%\n",
      "\n",
      "All patterns are cumulative (as expected by design)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS 2: FORECAST_HORIZON DOMINANCE TEST\n",
      "================================================================================\n",
      "Testing if model relies too heavily on forecast_horizon vs actual features\n",
      "--------------------------------------------------------------------------------\n",
      "Train samples: 1895, Val samples: 830\n",
      "\n",
      "--- Test 1: Full Model (with forecast_horizon) ---\n",
      "Train R²: 0.9836\n",
      "Val R²: 0.5891\n",
      "\n",
      "Feature Importances (Full Model):\n",
      "             feature  importance\n",
      "0   forecast_horizon    0.332059\n",
      "5         count_365d    0.327771\n",
      "1  total_weight_365d    0.201447\n",
      "2            rate_90    0.048051\n",
      "4   total_weight_90d    0.047448\n",
      "6   recency_weighted    0.022251\n",
      "7    active_ratio_90    0.014462\n",
      "3    days_since_last    0.006512\n",
      "\n",
      "--- Test 2: Model WITHOUT forecast_horizon ---\n",
      "Train R²: 0.5764\n",
      "Val R²: 0.5188\n",
      "\n",
      "Feature Importances (No Horizon):\n",
      "             feature  importance\n",
      "4         count_365d    0.449479\n",
      "0  total_weight_365d    0.312613\n",
      "3   total_weight_90d    0.074112\n",
      "1            rate_90    0.073385\n",
      "5   recency_weighted    0.050250\n",
      "6    active_ratio_90    0.024917\n",
      "2    days_since_last    0.015244\n",
      "\n",
      "--- Test 3: Model with ONLY forecast_horizon ---\n",
      "Train R²: 0.0866\n",
      "Val R²: -0.0596\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "HORIZON DOMINANCE SUMMARY:\n",
      "--------------------------------------------------------------------------------\n",
      "Performance drop without horizon: 11.9%\n",
      "Horizon-only model achieves: -10.1% of full model performance\n",
      "Forecast_horizon importance: 0.332\n",
      "✓ Model shows reasonable balance between horizon and other features\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS 3: PREDICTION CONSISTENCY CHECK\n",
      "================================================================================\n",
      "For same rm_id, date, and features - do predictions scale reasonably with horizon?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sample predictions for same (rm_id, date) with different horizons:\n",
      "    rm_id train_date  actual_7  actual_150    pred_full_7  pred_full_150\n",
      "0  3125.0 2024-01-01  143000.0   3028260.0  118459.134496   2.782107e+06\n",
      "1  2981.0 2024-01-01       0.0     50980.0    6143.701792   1.025963e+05\n",
      "2  2147.0 2024-01-01       0.0     78100.0    1403.107485   1.349294e+05\n",
      "3  4044.0 2024-01-01       0.0     18800.0     697.053577   1.149912e+04\n",
      "4  3381.0 2024-01-01       0.0     31264.0     192.151562   2.848103e+04\n",
      "5  3125.0 2024-02-01  119740.0   3142380.0   95909.717221   2.818671e+06\n",
      "6  2981.0 2024-02-01   25560.0     25560.0   15348.802723   7.436065e+04\n",
      "7  2147.0 2024-02-01       0.0     89260.0    1498.653002   1.089592e+05\n",
      "8  4044.0 2024-02-01       0.0         0.0     149.222716   9.655727e+03\n",
      "9  3381.0 2024-02-01       0.0     41214.0     388.388530   1.603356e+04\n",
      "\n",
      "Ratio Analysis (150-day / 7-day):\n",
      "Actual ratio (mean): 30966.64\n",
      "Full model ratio (mean): 51.25\n",
      "No-horizon model ratio (mean): 1.00\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS 4: RM_ID DELIVERY PATTERN DIVERSITY\n",
      "================================================================================\n",
      "Do different RM_IDs have different delivery patterns?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Delivery pattern summary:\n",
      "             rm_id  total_deliveries  total_weight  avg_delivery_size  \\\n",
      "count    20.000000         20.000000  2.000000e+01          20.000000   \n",
      "mean   3160.550000       1566.750000  2.675174e+07       17798.610754   \n",
      "std     674.902135       5322.979793  8.185016e+07        7317.077434   \n",
      "min    2125.000000          2.000000  1.901200e+04        1757.631579   \n",
      "25%    2776.000000          7.500000  9.721750e+04       15028.287887   \n",
      "50%    3281.500000         37.000000  5.873530e+05       18790.639344   \n",
      "75%    3626.250000        202.250000  3.890320e+06       23908.844455   \n",
      "max    4081.000000      23616.000000  3.512443e+08       24801.211679   \n",
      "\n",
      "       std_delivery_size  avg_inter_arrival_days  std_inter_arrival_days  \n",
      "count          20.000000               20.000000               18.000000  \n",
      "mean         3880.548146               58.554847               72.968424  \n",
      "std          3039.029450               70.894512              128.795555  \n",
      "min           257.811301                0.081050                0.639622  \n",
      "25%           840.197383                4.983102               16.546988  \n",
      "50%          3513.596625               29.476950               28.553237  \n",
      "75%          6517.199892               91.553571               70.781198  \n",
      "max          9163.804031              279.600000              559.601912  \n",
      "\n",
      "Pattern diversity metrics:\n",
      "CV of avg_delivery_size: 0.411\n",
      "CV of avg_inter_arrival_days: 1.211\n",
      "\n",
      "[5] GENERATING VISUALIZATIONS\n",
      "✅ Saved: leakage_analysis.png\n",
      "\n",
      "================================================================================\n",
      "FINAL VERDICT\n",
      "================================================================================\n",
      "\n",
      "1. CUMULATIVE TARGETS:\n",
      "   100.0% of patterns are cumulative\n",
      "   ✓ This is EXPECTED by design - not a problem\n",
      "\n",
      "2. FORECAST_HORIZON DOMINANCE:\n",
      "   Horizon feature importance: 0.332\n",
      "   Performance drop without horizon: 11.9%\n",
      "   ⚠️  WARNING: Moderate dependence on forecast_horizon\n",
      "\n",
      "3. PREDICTION CONSISTENCY:\n",
      "   Ratio prediction error: 99.8%\n",
      "   ⚠️  Poor consistency - model not capturing delivery patterns well\n",
      "\n",
      "4. PATTERN DIVERSITY:\n",
      "   Coefficient of variation in delivery sizes: 0.411\n",
      "   ⚠️  Low diversity - RM_IDs are similar\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CRITICAL ISSUE ANALYSIS: LEAKAGE & PATTERN VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\n[1] LOADING DATA\")\n",
    "receivals = pd.read_csv('./Project_materials/data/kernel/receivals.csv')\n",
    "prediction_mapping = pd.read_csv('./Project_materials/data/prediction_mapping.csv')\n",
    "\n",
    "# Convert dates\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "receivals = receivals[receivals['net_weight'] > 0]\n",
    "receivals = receivals[receivals['rm_id'].notna()]\n",
    "receivals = receivals.sort_values('date_arrival')\n",
    "\n",
    "print(f\"Total receivals: {len(receivals)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RECREATE TRAINING DATA\n",
    "# ============================================================================\n",
    "print(\"\\n[2] RECREATING TRAINING DATA\")\n",
    "train_dates = pd.date_range(start='2024-01-01', end='2024-11-30', freq='MS')\n",
    "forecast_horizons = [7, 30, 60, 90, 150]\n",
    "\n",
    "training_data = []\n",
    "active_rm_ids = receivals[receivals['date_arrival'] >= '2024-01-01']['rm_id'].unique()\n",
    "\n",
    "for i, train_date in enumerate(train_dates):\n",
    "    for rm_id in active_rm_ids:\n",
    "        hist = receivals[\n",
    "            (receivals['rm_id'] == rm_id) &\n",
    "            (receivals['date_arrival'] < train_date)\n",
    "        ]\n",
    "        \n",
    "        if len(hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        cutoff_365 = train_date - timedelta(days=365)\n",
    "        cutoff_180 = train_date - timedelta(days=180)\n",
    "        cutoff_90 = train_date - timedelta(days=90)\n",
    "        cutoff_30 = train_date - timedelta(days=30)\n",
    "        \n",
    "        recent_365 = hist[hist['date_arrival'] >= cutoff_365]\n",
    "        recent_180 = hist[hist['date_arrival'] >= cutoff_180]\n",
    "        recent_90 = hist[hist['date_arrival'] >= cutoff_90]\n",
    "        recent_30 = hist[hist['date_arrival'] >= cutoff_30]\n",
    "        \n",
    "        if len(recent_365) > 0:\n",
    "            total_365 = recent_365['net_weight'].sum()\n",
    "            count_365 = len(recent_365)\n",
    "            days_since = (train_date - recent_365['date_arrival'].max()).days\n",
    "        else:\n",
    "            total_365 = count_365 = days_since = 0\n",
    "        \n",
    "        if len(recent_180) > 0:\n",
    "            total_180 = recent_180['net_weight'].sum()\n",
    "            count_180 = len(recent_180)\n",
    "        else:\n",
    "            total_180 = count_180 = 0\n",
    "        \n",
    "        if len(recent_90) > 0:\n",
    "            total_90 = recent_90['net_weight'].sum()\n",
    "            count_90 = len(recent_90)\n",
    "        else:\n",
    "            total_90 = count_90 = 0\n",
    "        \n",
    "        if len(recent_30) > 0:\n",
    "            total_30 = recent_30['net_weight'].sum()\n",
    "            count_30 = len(recent_30)\n",
    "            rate_30 = total_30 / 30\n",
    "        else:\n",
    "            total_30 = count_30 = rate_30 = 0\n",
    "        \n",
    "        rate_90 = total_90 / 90 if total_90 > 0 else 0\n",
    "        \n",
    "        if len(recent_90) > 0:\n",
    "            days_ago = (train_date - recent_90['date_arrival']).dt.days\n",
    "            weights = 1.0 / (days_ago + 1)\n",
    "            recency_weighted = (recent_90['net_weight'] * weights).sum()\n",
    "        else:\n",
    "            recency_weighted = 0\n",
    "        \n",
    "        if len(recent_90) > 0:\n",
    "            active_days_90 = recent_90['date_arrival'].dt.date.nunique()\n",
    "            active_ratio_90 = active_days_90 / 90\n",
    "        else:\n",
    "            active_ratio_90 = 0\n",
    "        \n",
    "        for horizon in forecast_horizons:\n",
    "            forecast_end = train_date + timedelta(days=horizon)\n",
    "            \n",
    "            actual = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] >= train_date) &\n",
    "                (receivals['date_arrival'] <= forecast_end)\n",
    "            ]\n",
    "            target = actual['net_weight'].sum()\n",
    "            \n",
    "            training_data.append({\n",
    "                'rm_id': rm_id,\n",
    "                'train_date': train_date,\n",
    "                'forecast_horizon': horizon,\n",
    "                'total_weight_365d': total_365,\n",
    "                'count_365d': count_365,\n",
    "                'days_since_last': days_since,\n",
    "                'total_weight_90d': total_90,\n",
    "                'count_90d': count_90,\n",
    "                'rate_90': rate_90,\n",
    "                'total_weight_180d': total_180,\n",
    "                'count_180d': count_180,\n",
    "                'total_30': total_30,\n",
    "                'count_30': count_30,\n",
    "                'rate_30': rate_30,\n",
    "                'recency_weighted': recency_weighted,\n",
    "                'active_ratio_90': active_ratio_90,\n",
    "                'target': target\n",
    "            })\n",
    "\n",
    "train_df = pd.DataFrame(training_data)\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS 1: CUMULATIVE PATTERN CHECK (EXPECTED BEHAVIOR)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 1: CUMULATIVE PATTERN CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(\"NOTE: Targets SHOULD be cumulative by design - this is expected!\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "leakage_check = []\n",
    "sample_rm_ids = train_df['rm_id'].value_counts().head(20).index  # Top 20 most frequent\n",
    "\n",
    "for rm_id in sample_rm_ids:\n",
    "    rm_data = train_df[train_df['rm_id'] == rm_id].sort_values(['train_date', 'forecast_horizon'])\n",
    "    for date in rm_data['train_date'].unique():\n",
    "        date_data = rm_data[rm_data['train_date'] == date].sort_values('forecast_horizon')\n",
    "        targets = date_data['target'].values\n",
    "        \n",
    "        if len(targets) == 5:  # Should have all 5 horizons\n",
    "            leakage_check.append({\n",
    "                'rm_id': rm_id,\n",
    "                'train_date': date,\n",
    "                'horizon_7': targets[0],\n",
    "                'horizon_30': targets[1], \n",
    "                'horizon_60': targets[2],\n",
    "                'horizon_90': targets[3],\n",
    "                'horizon_150': targets[4],\n",
    "                'is_cumulative': targets[0] <= targets[1] <= targets[2] <= targets[3] <= targets[4],\n",
    "                'has_deliveries_all_horizons': all(t > 0 for t in targets)\n",
    "            })\n",
    "\n",
    "leakage_df = pd.DataFrame(leakage_check)\n",
    "print(f\"\\nTotal samples checked: {len(leakage_df)}\")\n",
    "print(f\"Percentage of cumulative patterns: {leakage_df['is_cumulative'].mean() * 100:.1f}%\")\n",
    "print(f\"Percentage with deliveries in ALL horizons: {leakage_df['has_deliveries_all_horizons'].mean() * 100:.1f}%\")\n",
    "\n",
    "# Show examples of non-cumulative patterns (these are the interesting ones)\n",
    "non_cumulative = leakage_df[~leakage_df['is_cumulative']]\n",
    "if len(non_cumulative) > 0:\n",
    "    print(f\"\\nNon-cumulative patterns found: {len(non_cumulative)}\")\n",
    "    print(\"\\nExample non-cumulative patterns (first 5):\")\n",
    "    print(non_cumulative.head())\n",
    "else:\n",
    "    print(\"\\nAll patterns are cumulative (as expected by design)\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS 2: DOES FORECAST_HORIZON DOMINATE PREDICTIONS?\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 2: FORECAST_HORIZON DOMINANCE TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"Testing if model relies too heavily on forecast_horizon vs actual features\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Prepare data for modeling\n",
    "feature_cols = ['forecast_horizon', 'total_weight_365d', 'rate_90', 'days_since_last',\n",
    "                'total_weight_90d', 'count_365d', 'recency_weighted', 'active_ratio_90']\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df['target'].copy()\n",
    "\n",
    "# Train/val split (temporal)\n",
    "split_date = pd.to_datetime('2024-09-01')\n",
    "train_mask = train_df['train_date'] < split_date\n",
    "val_mask = train_df['train_date'] >= split_date\n",
    "\n",
    "X_train = X[train_mask]\n",
    "y_train = y[train_mask]\n",
    "X_val = X[val_mask]\n",
    "y_val = y[val_mask]\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}, Val samples: {len(X_val)}\")\n",
    "\n",
    "# Test 1: Model with ALL features\n",
    "print(\"\\n--- Test 1: Full Model (with forecast_horizon) ---\")\n",
    "rf_full = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
    "rf_full.fit(X_train, y_train)\n",
    "\n",
    "train_score_full = rf_full.score(X_train, y_train)\n",
    "val_score_full = rf_full.score(X_val, y_val)\n",
    "print(f\"Train R²: {train_score_full:.4f}\")\n",
    "print(f\"Val R²: {val_score_full:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "importances_full = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_full.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importances (Full Model):\")\n",
    "print(importances_full)\n",
    "\n",
    "# Test 2: Model WITHOUT forecast_horizon\n",
    "print(\"\\n--- Test 2: Model WITHOUT forecast_horizon ---\")\n",
    "feature_cols_no_horizon = [f for f in feature_cols if f != 'forecast_horizon']\n",
    "X_train_no_horizon = X_train[feature_cols_no_horizon]\n",
    "X_val_no_horizon = X_val[feature_cols_no_horizon]\n",
    "\n",
    "rf_no_horizon = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
    "rf_no_horizon.fit(X_train_no_horizon, y_train)\n",
    "\n",
    "train_score_no_horizon = rf_no_horizon.score(X_train_no_horizon, y_train)\n",
    "val_score_no_horizon = rf_no_horizon.score(X_val_no_horizon, y_val)\n",
    "print(f\"Train R²: {train_score_no_horizon:.4f}\")\n",
    "print(f\"Val R²: {val_score_no_horizon:.4f}\")\n",
    "\n",
    "importances_no_horizon = pd.DataFrame({\n",
    "    'feature': feature_cols_no_horizon,\n",
    "    'importance': rf_no_horizon.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importances (No Horizon):\")\n",
    "print(importances_no_horizon)\n",
    "\n",
    "# Test 3: Model with ONLY forecast_horizon\n",
    "print(\"\\n--- Test 3: Model with ONLY forecast_horizon ---\")\n",
    "X_train_only_horizon = X_train[['forecast_horizon']]\n",
    "X_val_only_horizon = X_val[['forecast_horizon']]\n",
    "\n",
    "rf_only_horizon = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
    "rf_only_horizon.fit(X_train_only_horizon, y_train)\n",
    "\n",
    "train_score_only_horizon = rf_only_horizon.score(X_train_only_horizon, y_train)\n",
    "val_score_only_horizon = rf_only_horizon.score(X_val_only_horizon, y_val)\n",
    "print(f\"Train R²: {train_score_only_horizon:.4f}\")\n",
    "print(f\"Val R²: {val_score_only_horizon:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"HORIZON DOMINANCE SUMMARY:\")\n",
    "print(\"-\"*80)\n",
    "performance_drop = (val_score_full - val_score_no_horizon) / val_score_full * 100\n",
    "horizon_only_performance = val_score_only_horizon / val_score_full * 100\n",
    "\n",
    "print(f\"Performance drop without horizon: {performance_drop:.1f}%\")\n",
    "print(f\"Horizon-only model achieves: {horizon_only_performance:.1f}% of full model performance\")\n",
    "print(f\"Forecast_horizon importance: {importances_full.iloc[0]['importance']:.3f}\" if importances_full.iloc[0]['feature'] == 'forecast_horizon' else f\"Forecast_horizon importance: {importances_full[importances_full['feature']=='forecast_horizon']['importance'].values[0]:.3f}\")\n",
    "\n",
    "if performance_drop > 50:\n",
    "    print(\"⚠️  CRITICAL: Model is HEAVILY dependent on forecast_horizon!\")\n",
    "elif performance_drop > 25:\n",
    "    print(\"⚠️  WARNING: Model has SIGNIFICANT dependence on forecast_horizon\")\n",
    "else:\n",
    "    print(\"✓ Model shows reasonable balance between horizon and other features\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS 3: SAME FEATURES, DIFFERENT HORIZONS - VARIANCE CHECK\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 3: PREDICTION CONSISTENCY CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(\"For same rm_id, date, and features - do predictions scale reasonably with horizon?\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Pick a few examples and check predictions\n",
    "sample_examples = train_df[train_df['rm_id'].isin(sample_rm_ids[:5])].groupby(['rm_id', 'train_date']).filter(lambda x: len(x) == 5)\n",
    "unique_combos = sample_examples[['rm_id', 'train_date']].drop_duplicates().head(10)\n",
    "\n",
    "consistency_check = []\n",
    "for _, row in unique_combos.iterrows():\n",
    "    subset = train_df[(train_df['rm_id'] == row['rm_id']) & (train_df['train_date'] == row['train_date'])].sort_values('forecast_horizon')\n",
    "    \n",
    "    if len(subset) == 5:\n",
    "        X_subset = subset[feature_cols]\n",
    "        \n",
    "        pred_full = rf_full.predict(X_subset)\n",
    "        pred_no_horizon = rf_no_horizon.predict(X_subset[feature_cols_no_horizon])\n",
    "        actual = subset['target'].values\n",
    "        \n",
    "        consistency_check.append({\n",
    "            'rm_id': row['rm_id'],\n",
    "            'train_date': row['train_date'],\n",
    "            'actual_7': actual[0],\n",
    "            'actual_150': actual[4],\n",
    "            'pred_full_7': pred_full[0],\n",
    "            'pred_full_150': pred_full[4],\n",
    "            'pred_no_horizon_7': pred_no_horizon[0],\n",
    "            'pred_no_horizon_150': pred_no_horizon[4],\n",
    "            'actual_ratio': actual[4] / (actual[0] + 1),\n",
    "            'pred_full_ratio': pred_full[4] / (pred_full[0] + 1),\n",
    "            'pred_no_horizon_ratio': pred_no_horizon[4] / (pred_no_horizon[0] + 1)\n",
    "        })\n",
    "\n",
    "consistency_df = pd.DataFrame(consistency_check)\n",
    "print(\"\\nSample predictions for same (rm_id, date) with different horizons:\")\n",
    "print(consistency_df[['rm_id', 'train_date', 'actual_7', 'actual_150', 'pred_full_7', 'pred_full_150']].head(10))\n",
    "\n",
    "print(\"\\nRatio Analysis (150-day / 7-day):\")\n",
    "print(f\"Actual ratio (mean): {consistency_df['actual_ratio'].mean():.2f}\")\n",
    "print(f\"Full model ratio (mean): {consistency_df['pred_full_ratio'].mean():.2f}\")\n",
    "print(f\"No-horizon model ratio (mean): {consistency_df['pred_no_horizon_ratio'].mean():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS 4: PER-RM_ID DELIVERY PATTERN ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 4: RM_ID DELIVERY PATTERN DIVERSITY\")\n",
    "print(\"=\"*80)\n",
    "print(\"Do different RM_IDs have different delivery patterns?\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate per-RM_ID delivery statistics\n",
    "rm_patterns = []\n",
    "for rm_id in sample_rm_ids:\n",
    "    rm_deliveries = receivals[receivals['rm_id'] == rm_id]\n",
    "    \n",
    "    if len(rm_deliveries) > 0:\n",
    "        # Calculate inter-arrival times\n",
    "        rm_deliveries_sorted = rm_deliveries.sort_values('date_arrival')\n",
    "        inter_arrival = rm_deliveries_sorted['date_arrival'].diff().dt.days.dropna()\n",
    "        \n",
    "        rm_patterns.append({\n",
    "            'rm_id': rm_id,\n",
    "            'total_deliveries': len(rm_deliveries),\n",
    "            'total_weight': rm_deliveries['net_weight'].sum(),\n",
    "            'avg_delivery_size': rm_deliveries['net_weight'].mean(),\n",
    "            'std_delivery_size': rm_deliveries['net_weight'].std(),\n",
    "            'avg_inter_arrival_days': inter_arrival.mean() if len(inter_arrival) > 0 else np.nan,\n",
    "            'std_inter_arrival_days': inter_arrival.std() if len(inter_arrival) > 0 else np.nan\n",
    "        })\n",
    "\n",
    "patterns_df = pd.DataFrame(rm_patterns)\n",
    "print(\"\\nDelivery pattern summary:\")\n",
    "print(patterns_df.describe())\n",
    "\n",
    "print(\"\\nPattern diversity metrics:\")\n",
    "print(f\"CV of avg_delivery_size: {patterns_df['avg_delivery_size'].std() / patterns_df['avg_delivery_size'].mean():.3f}\")\n",
    "print(f\"CV of avg_inter_arrival_days: {patterns_df['avg_inter_arrival_days'].std() / patterns_df['avg_inter_arrival_days'].mean():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n[5] GENERATING VISUALIZATIONS\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Feature importance comparison\n",
    "ax = axes[0, 0]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Full Model': importances_full.set_index('feature')['importance'],\n",
    "    'No Horizon': importances_no_horizon.set_index('feature')['importance']\n",
    "})\n",
    "comparison_df.plot(kind='barh', ax=ax)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance: Full vs No Horizon')\n",
    "ax.legend()\n",
    "\n",
    "# Plot 2: R² comparison\n",
    "ax = axes[0, 1]\n",
    "r2_comparison = pd.DataFrame({\n",
    "    'Model': ['Full Model', 'No Horizon', 'Only Horizon'],\n",
    "    'Train R²': [train_score_full, train_score_no_horizon, train_score_only_horizon],\n",
    "    'Val R²': [val_score_full, val_score_no_horizon, val_score_only_horizon]\n",
    "})\n",
    "x = np.arange(len(r2_comparison))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, r2_comparison['Train R²'], width, label='Train R²')\n",
    "ax.bar(x + width/2, r2_comparison['Val R²'], width, label='Val R²')\n",
    "ax.set_xlabel('Model Type')\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(r2_comparison['Model'], rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Actual vs predicted ratios\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(consistency_df['actual_ratio'], consistency_df['pred_full_ratio'], alpha=0.6, label='Full Model')\n",
    "ax.scatter(consistency_df['actual_ratio'], consistency_df['pred_no_horizon_ratio'], alpha=0.6, label='No Horizon')\n",
    "ax.plot([0, consistency_df['actual_ratio'].max()], [0, consistency_df['actual_ratio'].max()], 'r--', label='Perfect')\n",
    "ax.set_xlabel('Actual Ratio (150d/7d)')\n",
    "ax.set_ylabel('Predicted Ratio (150d/7d)')\n",
    "ax.set_title('Horizon Ratio Prediction Consistency')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Delivery pattern diversity\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(patterns_df['avg_inter_arrival_days'], patterns_df['avg_delivery_size'], \n",
    "           s=patterns_df['total_deliveries']*2, alpha=0.6)\n",
    "ax.set_xlabel('Avg Inter-arrival Days')\n",
    "ax.set_ylabel('Avg Delivery Size (kg)')\n",
    "ax.set_title('RM_ID Delivery Pattern Diversity\\n(size = total deliveries)')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('leakage_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✅ Saved: leakage_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL VERDICT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. CUMULATIVE TARGETS:\")\n",
    "cumulative_pct = leakage_df['is_cumulative'].mean() * 100\n",
    "print(f\"   {cumulative_pct:.1f}% of patterns are cumulative\")\n",
    "print(\"   ✓ This is EXPECTED by design - not a problem\")\n",
    "\n",
    "print(\"\\n2. FORECAST_HORIZON DOMINANCE:\")\n",
    "horizon_importance = importances_full[importances_full['feature']=='forecast_horizon']['importance'].values[0]\n",
    "print(f\"   Horizon feature importance: {horizon_importance:.3f}\")\n",
    "print(f\"   Performance drop without horizon: {performance_drop:.1f}%\")\n",
    "if horizon_importance > 0.5 or performance_drop > 50:\n",
    "    print(\"   ⚠️  CRITICAL ISSUE: Model is over-reliant on forecast_horizon\")\n",
    "    print(\"   This suggests the model is learning the cumulative pattern, not delivery dynamics\")\n",
    "elif horizon_importance > 0.3 or performance_drop > 25:\n",
    "    print(\"   ⚠️  WARNING: Moderate dependence on forecast_horizon\")\n",
    "else:\n",
    "    print(\"   ✓ Reasonable balance between horizon and other features\")\n",
    "\n",
    "print(\"\\n3. PREDICTION CONSISTENCY:\")\n",
    "ratio_error = abs(consistency_df['pred_full_ratio'].mean() - consistency_df['actual_ratio'].mean()) / consistency_df['actual_ratio'].mean() * 100\n",
    "print(f\"   Ratio prediction error: {ratio_error:.1f}%\")\n",
    "if ratio_error > 50:\n",
    "    print(\"   ⚠️  Poor consistency - model not capturing delivery patterns well\")\n",
    "else:\n",
    "    print(\"   ✓ Reasonable ratio consistency\")\n",
    "\n",
    "print(\"\\n4. PATTERN DIVERSITY:\")\n",
    "cv_delivery = patterns_df['avg_delivery_size'].std() / patterns_df['avg_delivery_size'].mean()\n",
    "print(f\"   Coefficient of variation in delivery sizes: {cv_delivery:.3f}\")\n",
    "if cv_delivery > 2.0:\n",
    "    print(\"   ✓ High diversity - RM_IDs have distinct delivery patterns\")\n",
    "else:\n",
    "    print(\"   ⚠️  Low diversity - RM_IDs are similar\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"=\"*80)\n",
    "if horizon_importance > 0.5:\n",
    "    print(\"• CRITICAL: Redesign features to capture actual delivery dynamics\")\n",
    "    print(\"• Consider: delivery frequency, seasonality, supplier patterns\")\n",
    "    print(\"• Avoid: Using horizon as a direct feature - use it only for target calculation\")\n",
    "if performance_drop > 50:\n",
    "    print(\"• Model is learning shortcuts - need more informative features\")\n",
    "if patterns_df['avg_inter_arrival_days'].std() > 100:\n",
    "    print(\"• High variability in delivery patterns - consider RM_ID-specific models\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
