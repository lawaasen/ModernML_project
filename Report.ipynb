{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03d2c99",
   "metadata": {},
   "source": [
    "# Project Report TDT4173\n",
    "\n",
    "The purpose of this report is to summarize all steps taken in our group in order to find fitting models/algorithms to the problem at hand. This will include exploratory data analysis, feature engineering, variuos predictors including boosting/bagging, as well as feature and model interpretations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a3a5a",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Planned actions](#planned-actions)\n",
    "1. [Exploratory data analysis](#Exploratory-data-analysis)\n",
    "    1. [Important observations](#Important-observations)\n",
    "    2. [Steps taken](#Exploratory-steps)\n",
    "2. [Feature engineering](#Feature-engineering)\n",
    "    1. [Important observations](#Feature-engineering-Important-observations)\n",
    "    2. [Steps taken](#Feature-engineering-Steps-taken)\n",
    "3. [Model training](#Model-training)\n",
    "    1. [Important observations](#Model-training-Important-observations)\n",
    "    2. [Steps taken](#Model-training-Steps-taken)\n",
    "4. [Model evaluation and interpretation](#Model-evaluation-and-interpretation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32fda31",
   "metadata": {},
   "source": [
    "## Planned actions\n",
    "\n",
    "1. Perform exploratory data analysis in order to get an understanding of the data and notice patters/dependencies.\n",
    "2. Using the results in data analysis, perform feature engineering on a simple model (xgboost and random forest).\n",
    "3. Use the engineered features on better models (boosting/bagging). \n",
    "4. When model performs to satisfaction, perform model interpretation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d562e",
   "metadata": {},
   "source": [
    "## Exploratory data analysis: \n",
    "\n",
    "The purpose of performing an exploratory data analysis is to get an understanding of the different types of data included in the problem and their relations. This will be useful when creating models in order to understand why different models perform a certain way as how feature engineering can help improve performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dabe6a",
   "metadata": {},
   "source": [
    "### Important observations\n",
    "\n",
    "This section will summarize the steps taken in next subsection, and will include the most important observations taken during testing.\n",
    "\n",
    "- There are 33171 purchase orders and 122590 receivals. It is thus evident that there is a tendency that purchase orders are split into several receivals, either due to stock unavailability, large orders or other reasons. We may try to merge the two dataframes together using purchase order id´s, but this is dependent on them existing in both dataframes. If they do not, we may consider deleting the id´s. \n",
    "\n",
    "- In both receivals and purchase orders, there are a few NaN values in the different features. Proposed solution is to drop these rows. The column `batch_id` in the receivals dataframe has about half of its values as NaN. Proposed solution is to either drop this column, or combine the non-NaN rows (aka the batches) and then drop the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14e180",
   "metadata": {},
   "source": [
    "\n",
    "### Steps taken\n",
    "\n",
    "This section describes all the steps taken in the exploratory data analysis. All steps taken are to be included here and may include old steps not discussed further. In further sections we may observe new data patterns, which will be noted here. \n",
    "\n",
    "#### 07.10.:\n",
    "- Converted date columns to datetime format, and visualized the head of the dataframes to get an understanding of the data.\n",
    "\n",
    "- Checked the amount of NaN values in the receivals dataframe. About half of the values in the `batch_id` column in the dataframe are NaN values. We could drop the entire column. A handful of NaN values in all other columns. There could be overlap between NaN values across features, but I propose to drop all rows with NaN values in the receivals dataframe. \n",
    "\n",
    "- Checked the amount of NaN values in the purchase orders dataframe. A few NaN values in the `unit` and `unit_id` columns. Could remove these rows as we cannot be certain of the unit of the purchase order. Most of the units are in 'kg' and a handful in 'pund'. Could either remove the rows with 'pund' or convert them to 'kg'.\n",
    "\n",
    "- In the `receival_status` column in the receivals dataframe, there are 142 orders that are not 'Completed'.\n",
    "\n",
    "- There are about 4400 purchase orders which are not 'Closed' in the `status` column in the purchase orders dataframe. This could be an important observation as these orders are not completed, and could be a reason for delay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971b5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db5e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_receivals = pd.read_csv('./Project_materials/data/kernel/receivals.csv')\n",
    "data_purchase_orders = pd.read_csv('./Project_materials/data/kernel/purchase_orders.csv')\n",
    "# data_materials = pd.read_csv('./Project_materials/data/extended/materials.csv')\n",
    "# data_transportation = pd.read_csv('./Project_materials/data/extended/transportation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc070676",
   "metadata": {},
   "source": [
    "#### Printing dataframe heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838ab5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of receivals:  122590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_order_id</th>\n",
       "      <th>purchase_order_item_no</th>\n",
       "      <th>receival_item_no</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>receival_status</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>supplier_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208545.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-15 11:34:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>11420.0</td>\n",
       "      <td>52062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208545.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-15 11:34:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>13760.0</td>\n",
       "      <td>52062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208490.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-15 11:38:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>11281.0</td>\n",
       "      <td>50468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208490.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-15 11:38:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>13083.0</td>\n",
       "      <td>50468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>379.0</td>\n",
       "      <td>91900296.0</td>\n",
       "      <td>210435.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-15 11:40:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>23910.0</td>\n",
       "      <td>52577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rm_id  product_id  purchase_order_id  purchase_order_item_no  \\\n",
       "0  365.0  91900143.0           208545.0                    10.0   \n",
       "1  365.0  91900143.0           208545.0                    10.0   \n",
       "2  365.0  91900143.0           208490.0                    10.0   \n",
       "3  365.0  91900143.0           208490.0                    10.0   \n",
       "4  379.0  91900296.0           210435.0                    20.0   \n",
       "\n",
       "   receival_item_no  batch_id        date_arrival receival_status  net_weight  \\\n",
       "0                 1       NaN 2004-06-15 11:34:00       Completed     11420.0   \n",
       "1                 2       NaN 2004-06-15 11:34:00       Completed     13760.0   \n",
       "2                 1       NaN 2004-06-15 11:38:00       Completed     11281.0   \n",
       "3                 2       NaN 2004-06-15 11:38:00       Completed     13083.0   \n",
       "4                 1       NaN 2004-06-15 11:40:00       Completed     23910.0   \n",
       "\n",
       "   supplier_id  \n",
       "0        52062  \n",
       "1        52062  \n",
       "2        50468  \n",
       "3        50468  \n",
       "4        52577  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_receivals['date_arrival'] = pd.to_datetime(data_receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "print(\"Amount of receivals: \", len(data_receivals['rm_id']))\n",
    "data_receivals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1022a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of purchase orders:  33171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_order_id</th>\n",
       "      <th>purchase_order_item_no</th>\n",
       "      <th>quantity</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_version</th>\n",
       "      <th>created_date_time</th>\n",
       "      <th>modified_date_time</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>status_id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>2003-05-11 22:00:00</td>\n",
       "      <td>91900143</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-05-12 10:00:48</td>\n",
       "      <td>2004-06-15 06:16:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>23880.0</td>\n",
       "      <td>2003-05-26 22:00:00</td>\n",
       "      <td>91900160</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-05-27 12:42:07</td>\n",
       "      <td>2012-06-29 09:41:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004-03-07 23:00:00</td>\n",
       "      <td>91900143</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-03-08 13:44:31</td>\n",
       "      <td>2012-07-04 13:51:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004-03-09 23:00:00</td>\n",
       "      <td>91900143</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-03-10 11:39:06</td>\n",
       "      <td>2012-07-04 13:50:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>10</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>2004-10-27 22:00:00</td>\n",
       "      <td>91900143</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-10-22 12:21:54</td>\n",
       "      <td>2012-07-04 13:50:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_order_id  purchase_order_item_no  quantity       delivery_date  \\\n",
       "0                  1                       1     -14.0 2003-05-11 22:00:00   \n",
       "1                 22                       1   23880.0 2003-05-26 22:00:00   \n",
       "2                 41                       1       0.0 2004-03-07 23:00:00   \n",
       "3                 61                       1       0.0 2004-03-09 23:00:00   \n",
       "4                141                      10   25000.0 2004-10-27 22:00:00   \n",
       "\n",
       "   product_id  product_version   created_date_time  modified_date_time  \\\n",
       "0    91900143                1 2003-05-12 10:00:48 2004-06-15 06:16:18   \n",
       "1    91900160                1 2003-05-27 12:42:07 2012-06-29 09:41:13   \n",
       "2    91900143                1 2004-03-08 13:44:31 2012-07-04 13:51:02   \n",
       "3    91900143                1 2004-03-10 11:39:06 2012-07-04 13:50:59   \n",
       "4    91900143                1 2004-10-22 12:21:54 2012-07-04 13:50:55   \n",
       "\n",
       "   unit_id unit  status_id  status  \n",
       "0      NaN  NaN          2  Closed  \n",
       "1      NaN  NaN          2  Closed  \n",
       "2      NaN  NaN          2  Closed  \n",
       "3      NaN  NaN          2  Closed  \n",
       "4      NaN  NaN          2  Closed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_purchase_orders['delivery_date'] = pd.to_datetime(data_purchase_orders['delivery_date'], utc=True).dt.tz_localize(None)\n",
    "data_purchase_orders['created_date_time'] = pd.to_datetime(data_purchase_orders['created_date_time'], utc=True).dt.tz_localize(None)\n",
    "data_purchase_orders['modified_date_time'] = pd.to_datetime(data_purchase_orders['modified_date_time'], utc=True).dt.tz_localize(None)\n",
    "print(\"Amount of purchase orders: \", len(data_purchase_orders['purchase_order_id']))\n",
    "data_purchase_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f66aa4",
   "metadata": {},
   "source": [
    "#### Study of column values, especially NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42433e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_nan = 0\n",
    "for elmt in data_receivals['net_weight']:\n",
    "    if pd.isna(elmt):\n",
    "        num_nan += 1\n",
    "\n",
    "print(num_nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1218eb",
   "metadata": {},
   "source": [
    "#### 16.10.: Initial Modeling & Lag Analysis\n",
    "\n",
    "**Baseline Models**:\n",
    "- Started with simple rule-based baseline (0 for inactive, 75% of PO qty for active) → Score: 134,136 (beat 0 VTs) ❌\n",
    "- Moved to XGBoost with basic features (365d, 90d aggregates, PO data) + quantile regression (α=0.2) → Score: 10,135 (beat 2 VTs) ✅\n",
    "\n",
    "**Lag Pattern Discovery**:\n",
    "- Analyzed delivery lag (actual arrival - expected delivery date)\n",
    "- Key finding: Median lag = -15 days (deliveries arrive ~2 weeks EARLY!)\n",
    "- Supplier-specific variation: std dev of 47.3 days across suppliers → significant\n",
    "- Product-specific variation: std dev of 11.4 days\n",
    "- Temporal stability: 2020+ data is stable (2004-2006 had weird patterns, excluded from lag calc)\n",
    "\n",
    "**Lag Adjustment Implementation**:\n",
    "- Computed supplier-specific median lags from 2020+ data\n",
    "- Adjusted PO expected_arrival = delivery_date + supplier_lag\n",
    "- Only count POs with expected_arrival in forecast window (critical!)\n",
    "- XGBoost with lag adjustment → Score: 10,135 ✅\n",
    "- LightGBM with lag adjustment → Score: 9,600 ✅ (best so far!)\n",
    "\n",
    "**Failed Experiments**:\n",
    "- Random Forest with mean predictions → Score: 16,763 ❌ (RF needs 20th percentile extraction, too slow for iteration)\n",
    "- Ensemble XGBoost + LightGBM → No improvement (models too correlated, -0.2% on validation)\n",
    "\n",
    "**Feature Engineering Attempts**:\n",
    "1. **2023-2024 training data + trend features + supplier categorical** → Score: 11,800 ❌\n",
    "   - Added: 30d, 180d aggregates, trend_ratio, acceleration, supplier_id as categorical\n",
    "   - Problem: 2023 data created distribution shift (2023 patterns ≠ 2025 patterns)\n",
    "   - Validation improved (24,248) but Kaggle worse → classic overfitting\n",
    "   \n",
    "2. **2024 data + supplier as categorical** → Score: 15,000 ❌❌\n",
    "   - Problem: LightGBM's categorical feature handling overfits with 87 suppliers on small dataset\n",
    "   - Learned: categorical_feature parameter is dangerous with limited data\n",
    "\n",
    "**Key Observations**:\n",
    "- LightGBM (9,600) slightly beats XGBoost (10,135) with same features\n",
    "- Lag adjustment is critical (improves ~16% from baseline)\n",
    "- More data ≠ better (2023 data hurts due to distribution shift)\n",
    "- Categorical features in LightGBM overfit easily\n",
    "- Validation loss can be misleading (need time-based validation for forecasting)\n",
    "- Random 80/20 split includes old patterns, but Kaggle tests on 2025 (unseen conditions)\n",
    "\n",
    "**Current Best**: LightGBM + lag adjustment (2024 data, 13 features) → 9,600 (beats 2-3 VTs)\n",
    "\n",
    "**Next Steps**: Test supplier_id as numeric feature (not categorical), add trend features carefully with 2024 data only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b9e1d",
   "metadata": {},
   "source": [
    "## Feature engineering:\n",
    "\n",
    "The purpose of performing feature engineering on the datasets is to increase the performance of a predicting model. This can for example be done by removing features, merge features or giving features extra \"weight\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558a4af",
   "metadata": {},
   "source": [
    "### Important observations\n",
    "\n",
    "This section will summarize the steps taken in next subsection, and will include the most important observations taken during feature engineering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be8b81",
   "metadata": {},
   "source": [
    "### Steps taken\n",
    "\n",
    "This section describes all the steps taken during feature engineering. All steps taken are to be included here and may include old steps not discussed further. In further sections we may observe new feature behaviour, which will also be noted here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8201e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d833710d",
   "metadata": {},
   "source": [
    "## Model training:\n",
    "\n",
    "This is the section where we will train different models on the data, and try to find the best model for the problem. At the end of this section we should have a model that performs well on the data, and is able to make good predictions on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e417bbb",
   "metadata": {},
   "source": [
    "### Important observations\n",
    "This section will summarize the steps taken in next subsection, and will include the most important observations taken during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9603e94",
   "metadata": {},
   "source": [
    "### Steps taken\n",
    "This section describes all the steps taken during model training. All steps taken are to be included here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05650e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10d4062f",
   "metadata": {},
   "source": [
    "## Model evaluation and interpretation:\n",
    "The purpose of this section is to evaluate the model performance and interpret the model. This will include feature importance, SHAP values and partial dependence plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712f58a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
