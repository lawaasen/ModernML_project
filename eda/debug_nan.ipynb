{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3148445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: NaN CORRELATION ISSUE\n",
      "================================================================================\n",
      "\n",
      "Total receivals after cleaning: 122383\n",
      "Date range: 2004-06-15 11:34:00 to 2024-12-19 13:36:00\n",
      "\n",
      "[1] REPLICATING DIAGNOSTIC EDA SAMPLING\n",
      "--------------------------------------------------------------------------------\n",
      "Sampling from 13 dates\n",
      "Using 30 rm_ids: [365. 379. 389. 369. 366.]...\n",
      "\n",
      "--- Processing date 1/13: 2024-09-01 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 2/13: 2024-09-08 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 3/13: 2024-09-15 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 4/13: 2024-09-22 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 5/13: 2024-09-29 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 6/13: 2024-10-06 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 7/13: 2024-10-13 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 8/13: 2024-10-20 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 9/13: 2024-10-27 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 10/13: 2024-11-03 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 11/13: 2024-11-10 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 12/13: 2024-11-17 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "--- Processing date 13/13: 2024-11-24 ---\n",
      "  Generated 30 samples for this date\n",
      "\n",
      "================================================================================\n",
      "Total samples generated: 390\n",
      "\n",
      "[2] CHECKING FOR CONSTANT/ZERO COLUMNS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "total_365:\n",
      "  Unique values: 1\n",
      "  Zero count: 390/390 (100.0%)\n",
      "  Non-zero count: 0/390 (0.0%)\n",
      "  Min: 0.00\n",
      "  Max: 0.00\n",
      "  Mean: 0.00\n",
      "  Std: 0.00\n",
      "\n",
      "total_90:\n",
      "  Unique values: 1\n",
      "  Zero count: 390/390 (100.0%)\n",
      "  Non-zero count: 0/390 (0.0%)\n",
      "  Min: 0.00\n",
      "  Max: 0.00\n",
      "  Mean: 0.00\n",
      "  Std: 0.00\n",
      "\n",
      "count_365:\n",
      "  Unique values: 1\n",
      "  Zero count: 390/390 (100.0%)\n",
      "  Non-zero count: 0/390 (0.0%)\n",
      "  Min: 0.00\n",
      "  Max: 0.00\n",
      "  Mean: 0.00\n",
      "  Std: 0.00\n",
      "\n",
      "daily_rate:\n",
      "  Unique values: 1\n",
      "  Zero count: 390/390 (100.0%)\n",
      "  Non-zero count: 0/390 (0.0%)\n",
      "  Min: 0.00\n",
      "  Max: 0.00\n",
      "  Mean: 0.00\n",
      "  Std: 0.00\n",
      "\n",
      "target:\n",
      "  Unique values: 1\n",
      "  Zero count: 390/390 (100.0%)\n",
      "  Non-zero count: 0/390 (0.0%)\n",
      "  Min: 0.00\n",
      "  Max: 0.00\n",
      "  Mean: 0.00\n",
      "  Std: 0.00\n",
      "\n",
      "[3] CHECKING VARIANCE (NaN correlation needs variance > 0)\n",
      "--------------------------------------------------------------------------------\n",
      "total_365           : variance = 0.000000\n",
      "  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\n",
      "total_90            : variance = 0.000000\n",
      "  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\n",
      "count_365           : variance = 0.000000\n",
      "  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\n",
      "daily_rate          : variance = 0.000000\n",
      "  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\n",
      "target              : variance = 0.000000\n",
      "  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\n",
      "\n",
      "[4] COMPUTING CORRELATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "Samples with target > 0: 0/390 (0.0%)\n",
      "⚠️  NOT ENOUGH NON-ZERO TARGETS TO COMPUTE CORRELATION\n",
      "\n",
      "[5] INSPECTING PROBLEM CASES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Samples with ALL features = 0: 390\n",
      "\n",
      "First few examples:\n",
      " rm_id train_date  total_365  total_90  count_365  target\n",
      " 365.0 2024-09-01          0         0          0     0.0\n",
      " 379.0 2024-09-01          0         0          0     0.0\n",
      " 389.0 2024-09-01          0         0          0     0.0\n",
      " 369.0 2024-09-01          0         0          0     0.0\n",
      " 366.0 2024-09-01          0         0          0     0.0\n",
      " 368.0 2024-09-01          0         0          0     0.0\n",
      " 367.0 2024-09-01          0         0          0     0.0\n",
      " 375.0 2024-09-01          0         0          0     0.0\n",
      " 388.0 2024-09-01          0         0          0     0.0\n",
      " 347.0 2024-09-01          0         0          0     0.0\n",
      "\n",
      "--- Checking history for rm_id=365.0 ---\n",
      "Total receivals for rm_id=365.0: 1722\n",
      "Date range: 2004-06-15 11:34:00 to 2005-03-30 13:42:00\n",
      "Total weight: 25616003.00\n",
      "\n",
      "Samples with features > 0 but target = 0: 0\n",
      "Samples with features = 0 but target > 0: 0\n",
      "\n",
      "[6] ANALYZING RM_ID SELECTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "First 30 rm_ids (as used in diagnostic): [ 365.  379.  389.  369.  366.  368.  367.  375.  388.  347.  357.  378.\n",
      "  342.  346.  364.  381.  354.  383.  360.  386.  345.  348.  358.  374.\n",
      "  353.  390.  380.  387. 1845.  343.]\n",
      "\n",
      "Out of 30 sampled rm_ids:\n",
      "  Active in Sep-Dec 2024: 0\n",
      "  Inactive in Sep-Dec 2024: 30\n",
      "\n",
      "--- Activity patterns for first 10 rm_ids ---\n",
      "rm_id=365.0: 1722 total deliveries, last on 2005-03-30 13:42:00\n",
      "rm_id=379.0: 151 total deliveries, last on 2005-03-18 13:59:00\n",
      "rm_id=389.0: 72 total deliveries, last on 2005-03-30 12:15:00\n",
      "rm_id=369.0: 142 total deliveries, last on 2005-03-30 09:31:00\n",
      "rm_id=366.0: 115 total deliveries, last on 2005-03-30 13:42:00\n",
      "rm_id=368.0: 286 total deliveries, last on 2005-03-18 12:26:00\n",
      "rm_id=367.0: 97 total deliveries, last on 2005-03-30 06:32:00\n",
      "rm_id=375.0: 268 total deliveries, last on 2005-03-30 12:45:00\n",
      "rm_id=388.0: 7 total deliveries, last on 2005-03-29 11:18:00\n",
      "rm_id=347.0: 5 total deliveries, last on 2004-09-03 12:46:00\n",
      "\n",
      "[7] TESTING WITH GUARANTEED NON-CONSTANT DATA\n",
      "--------------------------------------------------------------------------------\n",
      "Using top 10 most active rm_ids: [2130.0, 1903.0, 2160.0, 2140.0, 2142.0, 2182.0, 1906.0, 2132.0, 1909.0, 2134.0]\n",
      "\n",
      "Generated 65 samples from active rm_ids\n",
      "Samples with target > 0: 50\n",
      "Samples with total_365 > 0: 65\n",
      "\n",
      "Correlation (should NOT be NaN): +0.9582\n",
      "✅ Correlation works with active rm_ids!\n",
      "\n",
      "================================================================================\n",
      "DEBUG COMPLETE - Check output above for root cause\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "receivals = pd.read_csv('./Project_materials/data/kernel/receivals.csv')\n",
    "purchase_orders = pd.read_csv('./Project_materials/data/kernel/purchase_orders.csv')\n",
    "\n",
    "# Convert dates\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "purchase_orders['delivery_date'] = pd.to_datetime(purchase_orders['delivery_date'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DEBUG: NaN CORRELATION ISSUE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Clean data\n",
    "receivals = receivals[receivals['net_weight'] > 0]\n",
    "receivals = receivals[receivals['rm_id'].notna()]\n",
    "receivals = receivals.sort_values('date_arrival')\n",
    "\n",
    "print(f\"\\nTotal receivals after cleaning: {len(receivals)}\")\n",
    "print(f\"Date range: {receivals['date_arrival'].min()} to {receivals['date_arrival'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# REPLICATE THE EXACT SAMPLING LOGIC FROM DIAGNOSTIC EDA\n",
    "# ============================================================================\n",
    "print(\"\\n[1] REPLICATING DIAGNOSTIC EDA SAMPLING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "test_samples = []\n",
    "\n",
    "# Use same parameters as diagnostic\n",
    "sample_dates = pd.date_range('2024-09-01', '2024-11-30', freq='W')\n",
    "sample_rm_ids = receivals['rm_id'].unique()[:30]  # First 30 rm_ids\n",
    "\n",
    "print(f\"Sampling from {len(sample_dates)} dates\")\n",
    "print(f\"Using {len(sample_rm_ids)} rm_ids: {sample_rm_ids[:5]}...\")\n",
    "\n",
    "for i, train_date in enumerate(sample_dates):\n",
    "    print(f\"\\n--- Processing date {i+1}/{len(sample_dates)}: {train_date.date()} ---\")\n",
    "    \n",
    "    samples_this_date = 0\n",
    "    \n",
    "    for rm_id in sample_rm_ids:\n",
    "        hist = receivals[(receivals['rm_id'] == rm_id) & (receivals['date_arrival'] < train_date)]\n",
    "        \n",
    "        if len(hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Compute features (EXACT REPLICA)\n",
    "        cutoff_365 = train_date - timedelta(days=365)\n",
    "        cutoff_90 = train_date - timedelta(days=90)\n",
    "        recent_365 = hist[hist['date_arrival'] >= cutoff_365]\n",
    "        recent_90 = hist[hist['date_arrival'] >= cutoff_90]\n",
    "        \n",
    "        total_365 = recent_365['net_weight'].sum() if len(recent_365) > 0 else 0\n",
    "        total_90 = recent_90['net_weight'].sum() if len(recent_90) > 0 else 0\n",
    "        count_365 = len(recent_365)\n",
    "        \n",
    "        # Get actual delivery in next 30 days\n",
    "        forecast_end = train_date + timedelta(days=30)\n",
    "        actual = receivals[(receivals['rm_id'] == rm_id) & \n",
    "                          (receivals['date_arrival'] >= train_date) & \n",
    "                          (receivals['date_arrival'] <= forecast_end)]\n",
    "        target = actual['net_weight'].sum()\n",
    "        \n",
    "        test_samples.append({\n",
    "            'rm_id': rm_id,\n",
    "            'train_date': train_date,\n",
    "            'total_365': total_365,\n",
    "            'total_90': total_90,\n",
    "            'count_365': count_365,\n",
    "            'daily_rate': total_365 / 365 if total_365 > 0 else 0,\n",
    "            'target': target\n",
    "        })\n",
    "        \n",
    "        samples_this_date += 1\n",
    "    \n",
    "    print(f\"  Generated {samples_this_date} samples for this date\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total samples generated: {len(test_samples)}\")\n",
    "\n",
    "sample_df = pd.DataFrame(test_samples)\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 1: Check for all-zero or all-constant columns\n",
    "# ============================================================================\n",
    "print(\"\\n[2] CHECKING FOR CONSTANT/ZERO COLUMNS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for col in ['total_365', 'total_90', 'count_365', 'daily_rate', 'target']:\n",
    "    unique_vals = sample_df[col].nunique()\n",
    "    zero_count = (sample_df[col] == 0).sum()\n",
    "    nonzero_count = (sample_df[col] > 0).sum()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {unique_vals}\")\n",
    "    print(f\"  Zero count: {zero_count}/{len(sample_df)} ({zero_count/len(sample_df)*100:.1f}%)\")\n",
    "    print(f\"  Non-zero count: {nonzero_count}/{len(sample_df)} ({nonzero_count/len(sample_df)*100:.1f}%)\")\n",
    "    print(f\"  Min: {sample_df[col].min():.2f}\")\n",
    "    print(f\"  Max: {sample_df[col].max():.2f}\")\n",
    "    print(f\"  Mean: {sample_df[col].mean():.2f}\")\n",
    "    print(f\"  Std: {sample_df[col].std():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 2: Check variance\n",
    "# ============================================================================\n",
    "print(\"\\n[3] CHECKING VARIANCE (NaN correlation needs variance > 0)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for col in ['total_365', 'total_90', 'count_365', 'daily_rate', 'target']:\n",
    "    variance = sample_df[col].var()\n",
    "    print(f\"{col:20s}: variance = {variance:.6f}\")\n",
    "    if variance == 0:\n",
    "        print(f\"  ⚠️  ZERO VARIANCE - This will cause NaN correlation!\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 3: Compute correlations with detailed output\n",
    "# ============================================================================\n",
    "print(\"\\n[4] COMPUTING CORRELATIONS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Filter to only samples with non-zero target\n",
    "nonzero_target_df = sample_df[sample_df['target'] > 0].copy()\n",
    "print(f\"Samples with target > 0: {len(nonzero_target_df)}/{len(sample_df)} ({len(nonzero_target_df)/len(sample_df)*100:.1f}%)\")\n",
    "\n",
    "if len(nonzero_target_df) > 1:\n",
    "    print(\"\\n--- Correlation on ALL samples ---\")\n",
    "    try:\n",
    "        corr_all = sample_df[['total_365', 'total_90', 'count_365', 'daily_rate', 'target']].corr()['target'].drop('target')\n",
    "        for feat, corr in corr_all.items():\n",
    "            print(f\"{feat:20s}: {corr:+.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing correlation: {e}\")\n",
    "    \n",
    "    print(\"\\n--- Correlation on samples with target > 0 ---\")\n",
    "    try:\n",
    "        corr_nonzero = nonzero_target_df[['total_365', 'total_90', 'count_365', 'daily_rate', 'target']].corr()['target'].drop('target')\n",
    "        for feat, corr in corr_nonzero.items():\n",
    "            print(f\"{feat:20s}: {corr:+.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing correlation: {e}\")\n",
    "else:\n",
    "    print(\"⚠️  NOT ENOUGH NON-ZERO TARGETS TO COMPUTE CORRELATION\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 4: Detailed inspection of problem cases\n",
    "# ============================================================================\n",
    "print(\"\\n[5] INSPECTING PROBLEM CASES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Find samples where features are all zero\n",
    "all_zero_features = sample_df[\n",
    "    (sample_df['total_365'] == 0) & \n",
    "    (sample_df['total_90'] == 0) & \n",
    "    (sample_df['count_365'] == 0)\n",
    "]\n",
    "print(f\"\\nSamples with ALL features = 0: {len(all_zero_features)}\")\n",
    "\n",
    "if len(all_zero_features) > 0:\n",
    "    print(\"\\nFirst few examples:\")\n",
    "    print(all_zero_features[['rm_id', 'train_date', 'total_365', 'total_90', 'count_365', 'target']].head(10).to_string(index=False))\n",
    "    \n",
    "    # Check if these rm_ids have ANY history\n",
    "    problem_rm_id = all_zero_features.iloc[0]['rm_id']\n",
    "    print(f\"\\n--- Checking history for rm_id={problem_rm_id} ---\")\n",
    "    hist_for_problem = receivals[receivals['rm_id'] == problem_rm_id]\n",
    "    print(f\"Total receivals for rm_id={problem_rm_id}: {len(hist_for_problem)}\")\n",
    "    if len(hist_for_problem) > 0:\n",
    "        print(f\"Date range: {hist_for_problem['date_arrival'].min()} to {hist_for_problem['date_arrival'].max()}\")\n",
    "        print(f\"Total weight: {hist_for_problem['net_weight'].sum():.2f}\")\n",
    "\n",
    "# Find samples where features > 0 but target = 0\n",
    "features_positive_target_zero = sample_df[\n",
    "    (sample_df['total_365'] > 0) & \n",
    "    (sample_df['target'] == 0)\n",
    "]\n",
    "print(f\"\\nSamples with features > 0 but target = 0: {len(features_positive_target_zero)}\")\n",
    "\n",
    "# Find samples where features = 0 but target > 0  \n",
    "features_zero_target_positive = sample_df[\n",
    "    (sample_df['total_365'] == 0) & \n",
    "    (sample_df['target'] > 0)\n",
    "]\n",
    "print(f\"Samples with features = 0 but target > 0: {len(features_zero_target_positive)}\")\n",
    "\n",
    "if len(features_zero_target_positive) > 0:\n",
    "    print(\"\\nFirst few examples:\")\n",
    "    print(features_zero_target_positive[['rm_id', 'train_date', 'total_365', 'count_365', 'target']].head(5).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 5: Check the actual rm_ids being sampled\n",
    "# ============================================================================\n",
    "print(\"\\n[6] ANALYZING RM_ID SELECTION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nFirst 30 rm_ids (as used in diagnostic): {sample_rm_ids}\")\n",
    "\n",
    "# Check how many of these rm_ids have data in the sampling window\n",
    "active_in_window = []\n",
    "for rm_id in sample_rm_ids:\n",
    "    data_in_window = receivals[\n",
    "        (receivals['rm_id'] == rm_id) & \n",
    "        (receivals['date_arrival'] >= '2024-09-01') & \n",
    "        (receivals['date_arrival'] <= '2024-12-31')\n",
    "    ]\n",
    "    if len(data_in_window) > 0:\n",
    "        active_in_window.append(rm_id)\n",
    "\n",
    "print(f\"\\nOut of {len(sample_rm_ids)} sampled rm_ids:\")\n",
    "print(f\"  Active in Sep-Dec 2024: {len(active_in_window)}\")\n",
    "print(f\"  Inactive in Sep-Dec 2024: {len(sample_rm_ids) - len(active_in_window)}\")\n",
    "\n",
    "# Show activity pattern\n",
    "print(\"\\n--- Activity patterns for first 10 rm_ids ---\")\n",
    "for rm_id in sample_rm_ids[:10]:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    last_delivery = rm_data['date_arrival'].max() if len(rm_data) > 0 else None\n",
    "    total_deliveries = len(rm_data)\n",
    "    \n",
    "    print(f\"rm_id={rm_id}: {total_deliveries} total deliveries, last on {last_delivery}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTIC 6: Compare to what SHOULD work\n",
    "# ============================================================================\n",
    "print(\"\\n[7] TESTING WITH GUARANTEED NON-CONSTANT DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create a simple test case we KNOW should work\n",
    "simple_test = []\n",
    "\n",
    "# Use only rm_ids that are very active\n",
    "very_active_rm_ids = receivals['rm_id'].value_counts().head(10).index.tolist()\n",
    "print(f\"Using top 10 most active rm_ids: {very_active_rm_ids}\")\n",
    "\n",
    "for train_date in pd.date_range('2024-09-01', '2024-11-30', freq='W'):\n",
    "    for rm_id in very_active_rm_ids:\n",
    "        hist = receivals[(receivals['rm_id'] == rm_id) & (receivals['date_arrival'] < train_date)]\n",
    "        \n",
    "        if len(hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        cutoff_365 = train_date - timedelta(days=365)\n",
    "        recent_365 = hist[hist['date_arrival'] >= cutoff_365]\n",
    "        \n",
    "        total_365 = recent_365['net_weight'].sum() if len(recent_365) > 0 else 0\n",
    "        \n",
    "        forecast_end = train_date + timedelta(days=30)\n",
    "        actual = receivals[(receivals['rm_id'] == rm_id) & \n",
    "                          (receivals['date_arrival'] >= train_date) & \n",
    "                          (receivals['date_arrival'] <= forecast_end)]\n",
    "        target = actual['net_weight'].sum()\n",
    "        \n",
    "        # Only include if there's actual activity\n",
    "        if total_365 > 0 or target > 0:\n",
    "            simple_test.append({\n",
    "                'total_365': total_365,\n",
    "                'target': target\n",
    "            })\n",
    "\n",
    "simple_df = pd.DataFrame(simple_test)\n",
    "print(f\"\\nGenerated {len(simple_df)} samples from active rm_ids\")\n",
    "\n",
    "if len(simple_df) > 1:\n",
    "    print(f\"Samples with target > 0: {(simple_df['target'] > 0).sum()}\")\n",
    "    print(f\"Samples with total_365 > 0: {(simple_df['total_365'] > 0).sum()}\")\n",
    "    \n",
    "    try:\n",
    "        corr = simple_df['total_365'].corr(simple_df['target'])\n",
    "        print(f\"\\nCorrelation (should NOT be NaN): {corr:+.4f}\")\n",
    "        \n",
    "        if pd.isna(corr):\n",
    "            print(\"⚠️  STILL NaN! Deep issue with correlation computation.\")\n",
    "        else:\n",
    "            print(\"✅ Correlation works with active rm_ids!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEBUG COMPLETE - Check output above for root cause\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
