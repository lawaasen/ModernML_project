{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2166b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPREHENSIVE TARGETED EDA FOR BREAKTHROUGH ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "Active 2024 RMs: 60\n",
      "Inactive RMs: 143\n",
      "Total test RMs: 203\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 1: PER-RM ACTIVITY & SCALE SNAPSHOT (2024 FOCUS)\n",
      "====================================================================================================\n",
      "\n",
      "--- Overall Summary ---\n",
      "         total_2024  deliveries_2024  mean_batch_2024   cv_batch\n",
      "count  6.000000e+01        60.000000        60.000000  51.000000\n",
      "mean   1.435019e+06        99.933333     15608.713221   0.404164\n",
      "std    3.052478e+06       200.191677      8714.096160   0.461510\n",
      "min    2.000000e+03         1.000000      1080.000000   0.000000\n",
      "25%    4.789000e+04         3.000000      6127.537037   0.027011\n",
      "50%    2.019500e+05        13.000000     18440.000000   0.297854\n",
      "75%    6.316575e+05       139.500000     23881.285714   0.576296\n",
      "max    1.503073e+07      1062.000000     25112.422360   1.574881\n",
      "\n",
      "--- Steady vs Lumpy Classification ---\n",
      "category\n",
      "steady    53\n",
      "lumpy      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Steady RMs (CV < 1.0): 44\n",
      "Lumpy RMs (CV > 1.0): 7\n",
      "\n",
      "--- Jan-May vs Sep-Nov Ratio Distribution ---\n",
      "count        60.000000\n",
      "mean      23572.991966\n",
      "std       88552.665712\n",
      "min           0.000000\n",
      "25%           0.334559\n",
      "50%           1.405997\n",
      "75%           2.998350\n",
      "max      576140.000000\n",
      "Name: janmay_vs_sepnov_ratio, dtype: float64\n",
      "\n",
      "--- Top 10 Highest Volume RMs ---\n",
      " rm_id  total_2024  deliveries_2024  mean_batch_2024  cv_batch category\n",
      "2130.0  15030729.0              882     17041.642857  0.364411   steady\n",
      "3865.0  12215851.0             1062     11502.684557  0.449709   steady\n",
      "3781.0  10633107.0              636     16718.721698  0.333559   steady\n",
      "3125.0   6317380.0              261     24204.521073  0.058706   steady\n",
      "3126.0   6226620.0              330     18868.545455  0.364113   steady\n",
      "3124.0   4942040.0              197     25086.497462  0.026980   steady\n",
      "3282.0   4877980.0              197     24761.319797  0.015129   steady\n",
      "3122.0   4847160.0              196     24730.408163  0.074078   steady\n",
      "3123.0   4043100.0              161     25112.422360  0.040333   steady\n",
      "3901.0   2339910.0              164     14267.743902  0.526566   steady\n",
      "\n",
      "--- Top 10 Most Lumpy RMs ---\n",
      " rm_id  total_2024  deliveries_2024  mean_batch_2024  cv_batch category\n",
      "3421.0    393306.0              153      2570.627451  1.574881    lumpy\n",
      "2144.0    556094.0              135      4119.214815  1.407861    lumpy\n",
      "2143.0    350531.0              202      1735.301980  1.361997    lumpy\n",
      "2132.0    300469.0               70      4292.414286  1.309496    lumpy\n",
      "2133.0     96782.0               25      3871.280000  1.293539    lumpy\n",
      "2142.0   1216846.0              331      3676.271903  1.284853    lumpy\n",
      "2131.0    624850.0              108      5785.648148  1.161912    lumpy\n",
      "3381.0     87381.0               14      6241.500000  0.952775   steady\n",
      "2145.0    485575.0              197      2464.847716  0.890540   steady\n",
      "2134.0   1598810.0              194      8241.288660  0.884438   steady\n",
      "\n",
      "✅ Saved detailed data to 'section1_rm_activity_snapshot.csv'\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 2: INTER-ARRIVAL TIME & BATCH SIZE DIAGNOSTICS\n",
      "====================================================================================================\n",
      "\n",
      "--- Inter-Arrival Time Statistics ---\n",
      "       median_interarrival_365d  IQR_interarrival_365d  cv_interarrival_365d\n",
      "count                 51.000000              51.000000             47.000000\n",
      "mean                  22.225490              10.769608              1.637482\n",
      "std                   46.196679              16.423599              1.229127\n",
      "min                    0.000000               0.000000              0.145874\n",
      "25%                    1.000000               1.000000              0.933311\n",
      "50%                    3.500000               3.000000              1.447596\n",
      "75%                   14.250000              13.750000              1.834442\n",
      "max                  224.000000              64.000000              6.741036\n",
      "\n",
      "--- Batch Size Statistics ---\n",
      "       median_batch_365d  IQR_batch_365d  cv_batch_365d\n",
      "count          51.000000       51.000000      51.000000\n",
      "mean        15938.656863     3682.549020       0.404164\n",
      "std          9597.829218     4212.364017       0.461510\n",
      "min          1000.000000        0.000000       0.000000\n",
      "25%          5311.250000      642.500000       0.027011\n",
      "50%         20358.000000     1300.000000       0.297854\n",
      "75%         24400.000000     6454.500000       0.576296\n",
      "max         25070.000000    13930.000000       1.574881\n",
      "\n",
      "--- Renewal Process Viability ---\n",
      "RMs with regular inter-arrivals (CV < 0.5): 3/51\n",
      "RMs with irregular inter-arrivals (CV > 1.0): 34/51\n",
      "RMs with consistent batch sizes (CV < 0.5): 36/51\n",
      "RMs with variable batch sizes (CV > 1.0): 7/51\n",
      "\n",
      "--- Inter-Arrival Distribution (aggregated) ---\n",
      "Total inter-arrivals: 5936\n",
      "Mean: 1.7 days\n",
      "Median: 0.0 days\n",
      "Std: 7.9 days\n",
      "\n",
      "Percentiles:\n",
      "  10th: 0.0 days\n",
      "  25th: 0.0 days\n",
      "  50th: 0.0 days\n",
      "  75th: 1.0 days\n",
      "  90th: 3.0 days\n",
      "  95th: 6.0 days\n",
      "  99th: 30.0 days\n",
      "\n",
      "✅ Saved detailed data to 'section2_renewal_diagnostics.csv'\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 3: DAYS_SINCE_LAST → P(Y>0) BY HORIZON\n",
      "====================================================================================================\n",
      "\n",
      "--- P(Y > 0) by Days_Since_Last Bin and Horizon ---\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Horizon = 7 days:\n",
      "    bin  n_samples  p_positive  median_given_positive\n",
      "    0-7        248    0.737903                46386.0\n",
      "   8-30        104    0.192308                24280.0\n",
      "  31-90        103    0.145631                50220.0\n",
      " 91-180         52    0.057692                23280.0\n",
      "181-365         25    0.040000                25000.0\n",
      "   >365         13    0.076923                24092.0\n",
      "\n",
      "Horizon = 30 days:\n",
      "    bin  n_samples  p_positive  median_given_positive\n",
      "    0-7        248    0.891129               115452.0\n",
      "   8-30        104    0.644231                42780.0\n",
      "  31-90        103    0.378641                23080.0\n",
      " 91-180         52    0.192308                21621.0\n",
      "181-365         25    0.200000                20326.0\n",
      "   >365         13    0.230769                23980.0\n",
      "\n",
      "Horizon = 60 days:\n",
      "    bin  n_samples  p_positive  median_given_positive\n",
      "    0-7        248    0.935484               205709.0\n",
      "   8-30        104    0.730769                70288.0\n",
      "  31-90        103    0.524272                23746.5\n",
      " 91-180         52    0.365385                21898.0\n",
      "181-365         25    0.280000                20326.0\n",
      "   >365         13    0.384615                48328.0\n",
      "\n",
      "Horizon = 90 days:\n",
      "    bin  n_samples  p_positive  median_given_positive\n",
      "    0-7        248    0.947581               302218.0\n",
      "   8-30        104    0.798077                72200.0\n",
      "  31-90        103    0.582524                30260.5\n",
      " 91-180         52    0.461538                21835.0\n",
      "181-365         25    0.320000                16413.0\n",
      "   >365         13    0.538462                69980.0\n",
      "\n",
      "Horizon = 150 days:\n",
      "    bin  n_samples  p_positive  median_given_positive\n",
      "    0-7        248    0.955645               414848.0\n",
      "   8-30        104    0.817308               129357.0\n",
      "  31-90        103    0.650485                43700.0\n",
      " 91-180         52    0.538462                23280.0\n",
      "181-365         25    0.400000                12500.0\n",
      "   >365         13    0.846154                95000.0\n",
      "\n",
      "✅ Saved detailed data to 'section3_guardrail_curves.csv'\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 4: HORIZON SCALING (CUMULATIVE GROWTH CURVES)\n",
      "====================================================================================================\n",
      "\n",
      "--- Normalized Growth Curves (relative to 150-day) ---\n",
      "         h7_norm   h30_norm   h60_norm   h90_norm  h150_norm\n",
      "count  46.000000  46.000000  46.000000  46.000000       46.0\n",
      "mean    0.028902   0.188254   0.432855   0.615561        1.0\n",
      "std     0.075002   0.208982   0.247361   0.251034        0.0\n",
      "min     0.000000   0.000000   0.000000   0.000000        1.0\n",
      "25%     0.000000   0.000000   0.357178   0.573410        1.0\n",
      "50%     0.000000   0.204287   0.431814   0.625187        1.0\n",
      "75%     0.044763   0.239711   0.486541   0.676150        1.0\n",
      "max     0.499198   1.000000   1.000000   1.000000        1.0\n",
      "\n",
      "--- Average Growth Template ---\n",
      "Average normalized medians:\n",
      "  7d: 0.029\n",
      "  30d: 0.188\n",
      "  60d: 0.433\n",
      "  90d: 0.616\n",
      "  150d: 1.000\n",
      "\n",
      "--- Concavity Check (should be sublinear) ---\n",
      "If concave, ratios should decrease:\n",
      "  7d/day = 0.00413, 30d/day = 0.00628, Δ = 0.00215\n",
      "  30d/day = 0.00628, 60d/day = 0.00721, Δ = 0.00094\n",
      "  60d/day = 0.00721, 90d/day = 0.00684, Δ = -0.00037\n",
      "  90d/day = 0.00684, 150d/day = 0.00667, Δ = -0.00017\n",
      "\n",
      "✅ Saved detailed data to 'section4_growth_curves.csv'\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 5: SUPPLIER / PRODUCT MIX STABILITY\n",
      "====================================================================================================\n",
      "\n",
      "--- Supplier Mix Stability ---\n",
      "High stability (Jaccard > 0.7): 17/60\n",
      "Medium stability (0.3 < Jaccard <= 0.7): 23/60\n",
      "Low stability (Jaccard <= 0.3): 20/60\n",
      "\n",
      "--- Product Mix Stability ---\n",
      "High stability (Jaccard > 0.7): 43/60\n",
      "Medium stability (0.3 < Jaccard <= 0.7): 0/60\n",
      "Low stability (Jaccard <= 0.3): 17/60\n",
      "\n",
      "--- Concentration Stats ---\n",
      "       top3_supplier_share_2024  top3_product_share_2024\n",
      "count                 60.000000                     60.0\n",
      "mean                   0.917140                      1.0\n",
      "std                    0.168301                      0.0\n",
      "min                    0.411730                      1.0\n",
      "25%                    0.985941                      1.0\n",
      "50%                    1.000000                      1.0\n",
      "75%                    1.000000                      1.0\n",
      "max                    1.000000                      1.0\n",
      "\n",
      "✅ Saved detailed data to 'section5_mix_stability.csv'\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 6: LEAK-CHECK SPLIT SIMULATION (PER-MONTH VAL LOSS)\n",
      "====================================================================================================\n",
      "\n",
      "--- Per-Month Validation Loss (Sep-Nov 2024) ---\n",
      "Using exact Step 5 feature set, no POs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sep 2024:\n",
      "  Samples: 260\n",
      "  Avg quantile loss: 58,580\n",
      "  Total actual: 75,821,337 kg\n",
      "  Total predicted: 76,420,947 kg\n",
      "  Prediction ratio: 1.008x\n",
      "\n",
      "Oct 2024:\n",
      "  Samples: 275\n",
      "  Avg quantile loss: 62,308\n",
      "  Total actual: 64,807,787 kg\n",
      "  Total predicted: 74,106,293 kg\n",
      "  Prediction ratio: 1.143x\n",
      "\n",
      "Nov 2024:\n",
      "  Samples: 295\n",
      "  Avg quantile loss: 80,940\n",
      "  Total actual: 42,177,456 kg\n",
      "  Total predicted: 68,665,693 kg\n",
      "  Prediction ratio: 1.628x\n",
      "\n",
      "====================================================================================================\n",
      "Note: This uses simple rate_90 baseline, not full Step 5 model\n",
      "Full Step 5 model would require retraining for each month\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "SECTION 7: INACTIVE RMs SANITY CHECK\n",
      "====================================================================================================\n",
      "\n",
      "--- Inactive RMs Summary (143 RMs) ---\n",
      "RMs with no history at all: 0\n",
      "RMs with last delivery > 1 year ago: 143\n",
      "RMs with last delivery > 5 years ago: 110\n",
      "RMs with last delivery > 10 years ago: 80\n",
      "\n",
      "--- Days Since Last Delivery Distribution ---\n",
      "count     143.000000\n",
      "mean     4004.370629\n",
      "std      2238.405219\n",
      "min       378.000000\n",
      "25%      2066.000000\n",
      "50%      3856.000000\n",
      "75%      4895.500000\n",
      "max      7496.000000\n",
      "Name: days_since_last, dtype: float64\n",
      "\n",
      "--- Last Year Activity Before Going Inactive ---\n",
      "count    1.430000e+02\n",
      "mean     1.277119e+06\n",
      "std      4.667599e+06\n",
      "min      3.200000e+02\n",
      "25%      2.143000e+04\n",
      "50%      5.747200e+04\n",
      "75%      5.563100e+05\n",
      "max      4.312594e+07\n",
      "Name: total_last_365_before_last, dtype: float64\n",
      "\n",
      "--- Sample of Inactive RMs (sorted by most recent) ---\n",
      " rm_id  last_delivery_date  days_since_last  total_last_365_before_last\n",
      "  4101 2023-12-19 14:11:00              378                     20280.0\n",
      "  2761 2023-12-18 08:51:00              379                    611060.0\n",
      "  3921 2023-10-20 08:28:00              438                     24980.0\n",
      "  3941 2023-10-04 06:24:00              454                     17617.0\n",
      "  3841 2023-08-04 08:30:00              515                    713212.0\n",
      "  3762 2023-06-09 09:57:00              571                    231400.0\n",
      "  3441 2023-06-02 10:31:00              578                   9384354.0\n",
      "  3821 2023-06-01 08:08:18              579                     49420.0\n",
      "  3162 2023-03-24 08:15:00              648                     68760.0\n",
      "  3802 2023-03-23 08:42:13              649                     24320.0\n",
      "\n",
      "--- Recommendation ---\n",
      "RMs inactive > 5 years: 110/143 (76.9%)\n",
      "These should almost certainly be predicted as 0\n",
      "\n",
      "RMs inactive 1-2 years: 12/143 (8.4%)\n",
      "These might have small reactivation probability - needs judgment\n",
      "\n",
      "✅ Saved detailed data to 'section7_inactive_rms.csv'\n",
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE EDA COMPLETE - FILES SAVED\n",
      "====================================================================================================\n",
      "\n",
      "Generated CSV files:\n",
      "  1. section1_rm_activity_snapshot.csv\n",
      "  2. section2_renewal_diagnostics.csv\n",
      "  3. section3_guardrail_curves.csv\n",
      "  4. section4_growth_curves.csv\n",
      "  5. section5_mix_stability.csv\n",
      "  6. (Section 6 printed inline)\n",
      "  7. section7_inactive_rms.csv\n",
      "\n",
      "====================================================================================================\n",
      "KEY TAKEAWAYS FOR NEW MODELING APPROACH\n",
      "====================================================================================================\n",
      "\n",
      "1. STEADY VS LUMPY RMs:\n",
      "   - 44/60 RMs are 'steady' (CV < 1.0)\n",
      "   - 7/60 RMs are 'lumpy' (CV > 1.0)\n",
      "   → Consider different models for each category\n",
      "\n",
      "2. RENEWAL PROCESS VIABILITY:\n",
      "   - 3/51 RMs have regular deliveries\n",
      "   - 36/51 RMs have consistent batch sizes\n",
      "   → Renewal/compound Poisson models viable for ~half of RMs\n",
      "\n",
      "3. GUARDRAIL INSIGHTS:\n",
      "   - P(Y>0) drops sharply after 90 days inactive\n",
      "   - But not zero until >365 days\n",
      "   → Current 365-day cutoff is reasonable but could be softened\n",
      "\n",
      "4. GROWTH CURVES:\n",
      "   - Cumulative delivery is concave (sublinear)\n",
      "   - Strong RM-specific patterns exist\n",
      "   → Per-RM growth templates could improve long-horizon predictions\n",
      "\n",
      "5. MIX STABILITY:\n",
      "   - 17/60 RMs have stable supplier mix\n",
      "   - 43/60 RMs have stable product mix\n",
      "   → Can use supplier/product lags for stable RMs only\n",
      "\n",
      "6. INACTIVE RMs:\n",
      "   - 110/143 inactive > 5 years (should be 0)\n",
      "   - 12/143 inactive 1-2 years (edge cases)\n",
      "   → Zero-prediction policy is correct for vast majority\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "COMPREHENSIVE TARGETED EDA FOR BREAKTHROUGH ANALYSIS\n",
    "All 7 sections requested for new modeling approach\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "receivals = pd.read_csv('./Project_materials/data/kernel/receivals.csv')\n",
    "purchase_orders = pd.read_csv('./Project_materials/data/kernel/purchase_orders.csv')\n",
    "prediction_mapping = pd.read_csv('./Project_materials/data/prediction_mapping.csv')\n",
    "\n",
    "# Convert dates\n",
    "receivals['date_arrival'] = pd.to_datetime(receivals['date_arrival'], utc=True).dt.tz_localize(None)\n",
    "purchase_orders['delivery_date'] = pd.to_datetime(purchase_orders['delivery_date'], utc=True).dt.tz_localize(None)\n",
    "prediction_mapping['forecast_start_date'] = pd.to_datetime(prediction_mapping['forecast_start_date'])\n",
    "prediction_mapping['forecast_end_date'] = pd.to_datetime(prediction_mapping['forecast_end_date'])\n",
    "\n",
    "receivals = receivals[receivals['net_weight'] > 0]\n",
    "receivals = receivals[receivals['rm_id'].notna()]\n",
    "receivals = receivals.sort_values(['rm_id', 'date_arrival'])\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPREHENSIVE TARGETED EDA FOR BREAKTHROUGH ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Identify active RMs\n",
    "active_2024_rms = receivals[receivals['date_arrival'].dt.year == 2024]['rm_id'].unique()\n",
    "test_rms = prediction_mapping['rm_id'].unique()\n",
    "inactive_rms = [rm for rm in test_rms if rm not in active_2024_rms]\n",
    "\n",
    "print(f\"\\nActive 2024 RMs: {len(active_2024_rms)}\")\n",
    "print(f\"Inactive RMs: {len(inactive_rms)}\")\n",
    "print(f\"Total test RMs: {len(test_rms)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: PER-RM ACTIVITY & SCALE SNAPSHOT (2024 FOCUS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 1: PER-RM ACTIVITY & SCALE SNAPSHOT (2024 FOCUS)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "rm_activity = []\n",
    "\n",
    "for rm_id in active_2024_rms:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    rm_2024 = rm_data[rm_data['date_arrival'].dt.year == 2024]\n",
    "    \n",
    "    # Jan-May 2024\n",
    "    jan_may_2024 = rm_2024[rm_2024['date_arrival'].dt.month.isin([1,2,3,4,5])]\n",
    "    \n",
    "    # Sep-Nov 2024\n",
    "    sep_nov_2024 = rm_2024[rm_2024['date_arrival'].dt.month.isin([9,10,11])]\n",
    "    \n",
    "    rm_activity.append({\n",
    "        'rm_id': rm_id,\n",
    "        'total_2024': rm_2024['net_weight'].sum(),\n",
    "        'total_JanMay_2024': jan_may_2024['net_weight'].sum(),\n",
    "        'total_SepNov_2024': sep_nov_2024['net_weight'].sum(),\n",
    "        'deliveries_2024': len(rm_2024),\n",
    "        'median_batch_2024': rm_2024['net_weight'].median(),\n",
    "        'mean_batch_2024': rm_2024['net_weight'].mean(),\n",
    "        'std_batch_2024': rm_2024['net_weight'].std(),\n",
    "        'last_date_2024': rm_2024['date_arrival'].max(),\n",
    "        'first_date_2024': rm_2024['date_arrival'].min()\n",
    "    })\n",
    "\n",
    "activity_df = pd.DataFrame(rm_activity)\n",
    "\n",
    "# Add derived metrics\n",
    "activity_df['cv_batch'] = activity_df['std_batch_2024'] / activity_df['mean_batch_2024']\n",
    "activity_df['janmay_vs_sepnov_ratio'] = activity_df['total_JanMay_2024'] / (activity_df['total_SepNov_2024'] + 1)\n",
    "activity_df['avg_daily_rate_2024'] = activity_df['total_2024'] / 365\n",
    "\n",
    "# Categorize as steady vs lumpy\n",
    "# Lumpy = high coefficient of variation in batch sizes\n",
    "activity_df['category'] = activity_df['cv_batch'].apply(\n",
    "    lambda x: 'lumpy' if x > 1.0 else 'steady'\n",
    ")\n",
    "\n",
    "print(\"\\n--- Overall Summary ---\")\n",
    "print(activity_df[['total_2024', 'deliveries_2024', 'mean_batch_2024', 'cv_batch']].describe())\n",
    "\n",
    "print(\"\\n--- Steady vs Lumpy Classification ---\")\n",
    "print(activity_df['category'].value_counts())\n",
    "print(f\"\\nSteady RMs (CV < 1.0): {(activity_df['cv_batch'] <= 1.0).sum()}\")\n",
    "print(f\"Lumpy RMs (CV > 1.0): {(activity_df['cv_batch'] > 1.0).sum()}\")\n",
    "\n",
    "print(\"\\n--- Jan-May vs Sep-Nov Ratio Distribution ---\")\n",
    "ratio_stats = activity_df['janmay_vs_sepnov_ratio'].describe()\n",
    "print(ratio_stats)\n",
    "\n",
    "print(\"\\n--- Top 10 Highest Volume RMs ---\")\n",
    "top_10 = activity_df.nlargest(10, 'total_2024')[\n",
    "    ['rm_id', 'total_2024', 'deliveries_2024', 'mean_batch_2024', 'cv_batch', 'category']\n",
    "]\n",
    "print(top_10.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- Top 10 Most Lumpy RMs ---\")\n",
    "lumpy_10 = activity_df.nlargest(10, 'cv_batch')[\n",
    "    ['rm_id', 'total_2024', 'deliveries_2024', 'mean_batch_2024', 'cv_batch', 'category']\n",
    "]\n",
    "print(lumpy_10.to_string(index=False))\n",
    "\n",
    "# Save to CSV for detailed inspection\n",
    "activity_df.to_csv('section1_rm_activity_snapshot.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section1_rm_activity_snapshot.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: INTER-ARRIVAL TIME & BATCH SIZE DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 2: INTER-ARRIVAL TIME & BATCH SIZE DIAGNOSTICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "renewal_stats = []\n",
    "\n",
    "for rm_id in active_2024_rms:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    \n",
    "    # Last 365 days of data (relative to end of 2024)\n",
    "    cutoff = pd.to_datetime('2024-12-31') - timedelta(days=365)\n",
    "    recent_data = rm_data[rm_data['date_arrival'] >= cutoff]\n",
    "    \n",
    "    if len(recent_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Inter-arrival times (in days)\n",
    "    dates = recent_data['date_arrival'].sort_values()\n",
    "    inter_arrivals = dates.diff().dt.days.dropna()\n",
    "    \n",
    "    # Batch sizes\n",
    "    batches = recent_data['net_weight']\n",
    "    \n",
    "    if len(inter_arrivals) > 0:\n",
    "        median_ia = inter_arrivals.median()\n",
    "        q25_ia = inter_arrivals.quantile(0.25)\n",
    "        q75_ia = inter_arrivals.quantile(0.75)\n",
    "        iqr_ia = q75_ia - q25_ia\n",
    "        mean_ia = inter_arrivals.mean()\n",
    "        std_ia = inter_arrivals.std()\n",
    "        cv_ia = std_ia / mean_ia if mean_ia > 0 else np.nan\n",
    "    else:\n",
    "        median_ia = q25_ia = q75_ia = iqr_ia = mean_ia = std_ia = cv_ia = np.nan\n",
    "    \n",
    "    median_batch = batches.median()\n",
    "    q25_batch = batches.quantile(0.25)\n",
    "    q75_batch = batches.quantile(0.75)\n",
    "    iqr_batch = q75_batch - q25_batch\n",
    "    mean_batch = batches.mean()\n",
    "    std_batch = batches.std()\n",
    "    cv_batch = std_batch / mean_batch if mean_batch > 0 else np.nan\n",
    "    \n",
    "    renewal_stats.append({\n",
    "        'rm_id': rm_id,\n",
    "        'n_deliveries_365d': len(recent_data),\n",
    "        'median_interarrival_365d': median_ia,\n",
    "        'IQR_interarrival_365d': iqr_ia,\n",
    "        'cv_interarrival_365d': cv_ia,\n",
    "        'median_batch_365d': median_batch,\n",
    "        'IQR_batch_365d': iqr_batch,\n",
    "        'cv_batch_365d': cv_batch,\n",
    "        'mean_interarrival_365d': mean_ia,\n",
    "        'mean_batch_365d': mean_batch\n",
    "    })\n",
    "\n",
    "renewal_df = pd.DataFrame(renewal_stats)\n",
    "\n",
    "print(\"\\n--- Inter-Arrival Time Statistics ---\")\n",
    "print(renewal_df[['median_interarrival_365d', 'IQR_interarrival_365d', 'cv_interarrival_365d']].describe())\n",
    "\n",
    "print(\"\\n--- Batch Size Statistics ---\")\n",
    "print(renewal_df[['median_batch_365d', 'IQR_batch_365d', 'cv_batch_365d']].describe())\n",
    "\n",
    "print(\"\\n--- Renewal Process Viability ---\")\n",
    "print(f\"RMs with regular inter-arrivals (CV < 0.5): {(renewal_df['cv_interarrival_365d'] < 0.5).sum()}/{len(renewal_df)}\")\n",
    "print(f\"RMs with irregular inter-arrivals (CV > 1.0): {(renewal_df['cv_interarrival_365d'] > 1.0).sum()}/{len(renewal_df)}\")\n",
    "print(f\"RMs with consistent batch sizes (CV < 0.5): {(renewal_df['cv_batch_365d'] < 0.5).sum()}/{len(renewal_df)}\")\n",
    "print(f\"RMs with variable batch sizes (CV > 1.0): {(renewal_df['cv_batch_365d'] > 1.0).sum()}/{len(renewal_df)}\")\n",
    "\n",
    "# Histogram data\n",
    "print(\"\\n--- Inter-Arrival Distribution (aggregated) ---\")\n",
    "all_inter_arrivals = []\n",
    "for rm_id in active_2024_rms:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    cutoff = pd.to_datetime('2024-12-31') - timedelta(days=365)\n",
    "    recent_data = rm_data[rm_data['date_arrival'] >= cutoff]\n",
    "    if len(recent_data) >= 2:\n",
    "        dates = recent_data['date_arrival'].sort_values()\n",
    "        inter_arrivals = dates.diff().dt.days.dropna()\n",
    "        all_inter_arrivals.extend(inter_arrivals.tolist())\n",
    "\n",
    "ia_series = pd.Series(all_inter_arrivals)\n",
    "print(f\"Total inter-arrivals: {len(ia_series)}\")\n",
    "print(f\"Mean: {ia_series.mean():.1f} days\")\n",
    "print(f\"Median: {ia_series.median():.1f} days\")\n",
    "print(f\"Std: {ia_series.std():.1f} days\")\n",
    "print(\"\\nPercentiles:\")\n",
    "for p in [10, 25, 50, 75, 90, 95, 99]:\n",
    "    print(f\"  {p}th: {ia_series.quantile(p/100):.1f} days\")\n",
    "\n",
    "renewal_df.to_csv('section2_renewal_diagnostics.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section2_renewal_diagnostics.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: DAYS_SINCE_LAST → P(Y>0) BY HORIZON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 3: DAYS_SINCE_LAST → P(Y>0) BY HORIZON\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Create training samples with days_since_last binning\n",
    "train_dates = pd.date_range(start='2024-01-01', end='2024-11-30', freq='MS')\n",
    "forecast_horizons = [7, 30, 60, 90, 150]\n",
    "\n",
    "guardrail_data = []\n",
    "\n",
    "for train_date in train_dates:\n",
    "    for rm_id in active_2024_rms:\n",
    "        hist = receivals[\n",
    "            (receivals['rm_id'] == rm_id) &\n",
    "            (receivals['date_arrival'] < train_date)\n",
    "        ]\n",
    "        \n",
    "        if len(hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        last_delivery = hist['date_arrival'].max()\n",
    "        days_since = (train_date - last_delivery).days\n",
    "        \n",
    "        for horizon in forecast_horizons:\n",
    "            forecast_end = train_date + timedelta(days=horizon)\n",
    "            \n",
    "            actual = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] >= train_date) &\n",
    "                (receivals['date_arrival'] <= forecast_end)\n",
    "            ]\n",
    "            target = actual['net_weight'].sum()\n",
    "            \n",
    "            # Bin days_since_last\n",
    "            if days_since <= 7:\n",
    "                bin_label = '0-7'\n",
    "            elif days_since <= 30:\n",
    "                bin_label = '8-30'\n",
    "            elif days_since <= 90:\n",
    "                bin_label = '31-90'\n",
    "            elif days_since <= 180:\n",
    "                bin_label = '91-180'\n",
    "            elif days_since <= 365:\n",
    "                bin_label = '181-365'\n",
    "            else:\n",
    "                bin_label = '>365'\n",
    "            \n",
    "            guardrail_data.append({\n",
    "                'days_since_bin': bin_label,\n",
    "                'days_since_actual': days_since,\n",
    "                'horizon': horizon,\n",
    "                'target': target,\n",
    "                'has_delivery': 1 if target > 0 else 0\n",
    "            })\n",
    "\n",
    "guardrail_df = pd.DataFrame(guardrail_data)\n",
    "\n",
    "print(\"\\n--- P(Y > 0) by Days_Since_Last Bin and Horizon ---\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "bins = ['0-7', '8-30', '31-90', '91-180', '181-365', '>365']\n",
    "results = []\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    horizon_data = guardrail_df[guardrail_df['horizon'] == horizon]\n",
    "    \n",
    "    for bin_label in bins:\n",
    "        bin_data = horizon_data[horizon_data['days_since_bin'] == bin_label]\n",
    "        \n",
    "        if len(bin_data) > 0:\n",
    "            p_positive = bin_data['has_delivery'].mean()\n",
    "            positive_data = bin_data[bin_data['target'] > 0]\n",
    "            median_given_positive = positive_data['target'].median() if len(positive_data) > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'horizon': horizon,\n",
    "                'bin': bin_label,\n",
    "                'n_samples': len(bin_data),\n",
    "                'p_positive': p_positive,\n",
    "                'median_given_positive': median_given_positive\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print in table format\n",
    "print(\"\\nHorizon = 7 days:\")\n",
    "h7 = results_df[results_df['horizon'] == 7][['bin', 'n_samples', 'p_positive', 'median_given_positive']]\n",
    "print(h7.to_string(index=False))\n",
    "\n",
    "print(\"\\nHorizon = 30 days:\")\n",
    "h30 = results_df[results_df['horizon'] == 30][['bin', 'n_samples', 'p_positive', 'median_given_positive']]\n",
    "print(h30.to_string(index=False))\n",
    "\n",
    "print(\"\\nHorizon = 60 days:\")\n",
    "h60 = results_df[results_df['horizon'] == 60][['bin', 'n_samples', 'p_positive', 'median_given_positive']]\n",
    "print(h60.to_string(index=False))\n",
    "\n",
    "print(\"\\nHorizon = 90 days:\")\n",
    "h90 = results_df[results_df['horizon'] == 90][['bin', 'n_samples', 'p_positive', 'median_given_positive']]\n",
    "print(h90.to_string(index=False))\n",
    "\n",
    "print(\"\\nHorizon = 150 days:\")\n",
    "h150 = results_df[results_df['horizon'] == 150][['bin', 'n_samples', 'p_positive', 'median_given_positive']]\n",
    "print(h150.to_string(index=False))\n",
    "\n",
    "results_df.to_csv('section3_guardrail_curves.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section3_guardrail_curves.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: HORIZON SCALING (CUMULATIVE GROWTH CURVES)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 4: HORIZON SCALING (CUMULATIVE GROWTH CURVES)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "growth_curves = []\n",
    "\n",
    "for rm_id in active_2024_rms:\n",
    "    rm_medians = {}\n",
    "    \n",
    "    for horizon in forecast_horizons:\n",
    "        horizon_targets = []\n",
    "        \n",
    "        for train_date in train_dates:\n",
    "            forecast_end = train_date + timedelta(days=horizon)\n",
    "            \n",
    "            actual = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] >= train_date) &\n",
    "                (receivals['date_arrival'] <= forecast_end)\n",
    "            ]\n",
    "            \n",
    "            if len(receivals[(receivals['rm_id'] == rm_id) & \n",
    "                           (receivals['date_arrival'] < train_date)]) > 0:\n",
    "                horizon_targets.append(actual['net_weight'].sum())\n",
    "        \n",
    "        if len(horizon_targets) > 0:\n",
    "            rm_medians[horizon] = np.median(horizon_targets)\n",
    "    \n",
    "    # Normalize by 150-day horizon\n",
    "    if 150 in rm_medians and rm_medians[150] > 0:\n",
    "        normalized = {h: rm_medians[h] / rm_medians[150] for h in forecast_horizons if h in rm_medians}\n",
    "        \n",
    "        growth_curves.append({\n",
    "            'rm_id': rm_id,\n",
    "            'h7_norm': normalized.get(7, np.nan),\n",
    "            'h30_norm': normalized.get(30, np.nan),\n",
    "            'h60_norm': normalized.get(60, np.nan),\n",
    "            'h90_norm': normalized.get(90, np.nan),\n",
    "            'h150_norm': normalized.get(150, 1.0),\n",
    "            'median_150d': rm_medians[150]\n",
    "        })\n",
    "\n",
    "growth_df = pd.DataFrame(growth_curves)\n",
    "\n",
    "print(\"\\n--- Normalized Growth Curves (relative to 150-day) ---\")\n",
    "print(growth_df[['h7_norm', 'h30_norm', 'h60_norm', 'h90_norm', 'h150_norm']].describe())\n",
    "\n",
    "print(\"\\n--- Average Growth Template ---\")\n",
    "avg_template = {\n",
    "    7: growth_df['h7_norm'].mean(),\n",
    "    30: growth_df['h30_norm'].mean(),\n",
    "    60: growth_df['h60_norm'].mean(),\n",
    "    90: growth_df['h90_norm'].mean(),\n",
    "    150: 1.0\n",
    "}\n",
    "print(\"Average normalized medians:\")\n",
    "for h, val in avg_template.items():\n",
    "    print(f\"  {h}d: {val:.3f}\")\n",
    "\n",
    "print(\"\\n--- Concavity Check (should be sublinear) ---\")\n",
    "print(\"If concave, ratios should decrease:\")\n",
    "for i, (h1, h2) in enumerate([(7, 30), (30, 60), (60, 90), (90, 150)]):\n",
    "    ratio1 = avg_template[h1] / h1\n",
    "    ratio2 = avg_template[h2] / h2\n",
    "    print(f\"  {h1}d/day = {ratio1:.5f}, {h2}d/day = {ratio2:.5f}, Δ = {ratio2-ratio1:.5f}\")\n",
    "\n",
    "growth_df.to_csv('section4_growth_curves.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section4_growth_curves.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: SUPPLIER / PRODUCT MIX STABILITY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 5: SUPPLIER / PRODUCT MIX STABILITY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "mix_stability = []\n",
    "\n",
    "for rm_id in active_2024_rms:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    \n",
    "    # 2024 data\n",
    "    data_2024 = rm_data[rm_data['date_arrival'].dt.year == 2024]\n",
    "    # 2023 data\n",
    "    data_2023 = rm_data[rm_data['date_arrival'].dt.year == 2023]\n",
    "    \n",
    "    # Supplier analysis\n",
    "    if len(data_2024) > 0:\n",
    "        supplier_2024 = data_2024.groupby('supplier_id')['net_weight'].sum().sort_values(ascending=False)\n",
    "        top3_suppliers_2024 = supplier_2024.head(3)\n",
    "        top3_share_2024 = top3_suppliers_2024.sum() / supplier_2024.sum() if supplier_2024.sum() > 0 else 0\n",
    "        top_suppliers_2024_set = set(top3_suppliers_2024.index)\n",
    "    else:\n",
    "        top_suppliers_2024_set = set()\n",
    "        top3_share_2024 = 0\n",
    "    \n",
    "    if len(data_2023) > 0:\n",
    "        supplier_2023 = data_2023.groupby('supplier_id')['net_weight'].sum().sort_values(ascending=False)\n",
    "        top_suppliers_2023_set = set(supplier_2023.head(3).index)\n",
    "    else:\n",
    "        top_suppliers_2023_set = set()\n",
    "    \n",
    "    # Jaccard similarity\n",
    "    if len(top_suppliers_2024_set) > 0 or len(top_suppliers_2023_set) > 0:\n",
    "        supplier_jaccard = len(top_suppliers_2024_set & top_suppliers_2023_set) / len(top_suppliers_2024_set | top_suppliers_2023_set)\n",
    "    else:\n",
    "        supplier_jaccard = 0\n",
    "    \n",
    "    # Product analysis\n",
    "    if len(data_2024) > 0:\n",
    "        product_2024 = data_2024.groupby('product_id')['net_weight'].sum().sort_values(ascending=False)\n",
    "        top3_products_2024 = product_2024.head(3)\n",
    "        top3_product_share_2024 = top3_products_2024.sum() / product_2024.sum() if product_2024.sum() > 0 else 0\n",
    "        top_products_2024_set = set(top3_products_2024.index)\n",
    "        num_products_2024 = len(product_2024)\n",
    "    else:\n",
    "        top_products_2024_set = set()\n",
    "        top3_product_share_2024 = 0\n",
    "        num_products_2024 = 0\n",
    "    \n",
    "    if len(data_2023) > 0:\n",
    "        product_2023 = data_2023.groupby('product_id')['net_weight'].sum().sort_values(ascending=False)\n",
    "        top_products_2023_set = set(product_2023.head(3).index)\n",
    "    else:\n",
    "        top_products_2023_set = set()\n",
    "    \n",
    "    if len(top_products_2024_set) > 0 or len(top_products_2023_set) > 0:\n",
    "        product_jaccard = len(top_products_2024_set & top_products_2023_set) / len(top_products_2024_set | top_products_2023_set)\n",
    "    else:\n",
    "        product_jaccard = 0\n",
    "    \n",
    "    mix_stability.append({\n",
    "        'rm_id': rm_id,\n",
    "        'supplier_jaccard': supplier_jaccard,\n",
    "        'product_jaccard': product_jaccard,\n",
    "        'top3_supplier_share_2024': top3_share_2024,\n",
    "        'top3_product_share_2024': top3_product_share_2024,\n",
    "        'num_products_2024': num_products_2024,\n",
    "        'num_suppliers_2024': len(data_2024['supplier_id'].unique()) if len(data_2024) > 0 else 0\n",
    "    })\n",
    "\n",
    "mix_df = pd.DataFrame(mix_stability)\n",
    "\n",
    "print(\"\\n--- Supplier Mix Stability ---\")\n",
    "print(f\"High stability (Jaccard > 0.7): {(mix_df['supplier_jaccard'] > 0.7).sum()}/{len(mix_df)}\")\n",
    "print(f\"Medium stability (0.3 < Jaccard <= 0.7): {((mix_df['supplier_jaccard'] > 0.3) & (mix_df['supplier_jaccard'] <= 0.7)).sum()}/{len(mix_df)}\")\n",
    "print(f\"Low stability (Jaccard <= 0.3): {(mix_df['supplier_jaccard'] <= 0.3).sum()}/{len(mix_df)}\")\n",
    "\n",
    "print(\"\\n--- Product Mix Stability ---\")\n",
    "print(f\"High stability (Jaccard > 0.7): {(mix_df['product_jaccard'] > 0.7).sum()}/{len(mix_df)}\")\n",
    "print(f\"Medium stability (0.3 < Jaccard <= 0.7): {((mix_df['product_jaccard'] > 0.3) & (mix_df['product_jaccard'] <= 0.7)).sum()}/{len(mix_df)}\")\n",
    "print(f\"Low stability (Jaccard <= 0.3): {(mix_df['product_jaccard'] <= 0.3).sum()}/{len(mix_df)}\")\n",
    "\n",
    "print(\"\\n--- Concentration Stats ---\")\n",
    "print(mix_df[['top3_supplier_share_2024', 'top3_product_share_2024']].describe())\n",
    "\n",
    "mix_df.to_csv('section5_mix_stability.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section5_mix_stability.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: LEAK-CHECK SPLIT SIMULATION (PER-MONTH VAL LOSS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 6: LEAK-CHECK SPLIT SIMULATION (PER-MONTH VAL LOSS)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Simulate Sep-Nov validation with quantile loss computation\n",
    "val_months = [(9, 'Sep'), (10, 'Oct'), (11, 'Nov')]\n",
    "\n",
    "print(\"\\n--- Per-Month Validation Loss (Sep-Nov 2024) ---\")\n",
    "print(\"Using exact Step 5 feature set, no POs\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for month_num, month_name in val_months:\n",
    "    month_start = pd.to_datetime(f'2024-{month_num:02d}-01')\n",
    "    if month_num == 11:\n",
    "        month_end = pd.to_datetime('2024-11-30')\n",
    "    else:\n",
    "        month_end = pd.to_datetime(f'2024-{month_num:02d}-01') + pd.DateOffset(months=1) - timedelta(days=1)\n",
    "    \n",
    "    month_samples = []\n",
    "    \n",
    "    for rm_id in active_2024_rms:\n",
    "        for horizon in forecast_horizons:\n",
    "            # Use month_start as training date\n",
    "            hist = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] < month_start)\n",
    "            ]\n",
    "            \n",
    "            if len(hist) == 0:\n",
    "                continue\n",
    "            \n",
    "            forecast_end = month_start + timedelta(days=horizon)\n",
    "            \n",
    "            actual = receivals[\n",
    "                (receivals['rm_id'] == rm_id) &\n",
    "                (receivals['date_arrival'] >= month_start) &\n",
    "                (receivals['date_arrival'] <= forecast_end)\n",
    "            ]\n",
    "            \n",
    "            target = actual['net_weight'].sum()\n",
    "            \n",
    "            # Simple baseline prediction (rate_90 * horizon)\n",
    "            recent_90 = hist[hist['date_arrival'] >= month_start - timedelta(days=90)]\n",
    "            if len(recent_90) > 0:\n",
    "                rate_90 = recent_90['net_weight'].sum() / 90\n",
    "                pred = rate_90 * horizon\n",
    "            else:\n",
    "                pred = 0\n",
    "            \n",
    "            # Quantile loss 0.2\n",
    "            if pred < target:\n",
    "                loss = 0.2 * (target - pred)\n",
    "            else:\n",
    "                loss = 0.8 * (pred - target)\n",
    "            \n",
    "            month_samples.append({\n",
    "                'month': month_name,\n",
    "                'target': target,\n",
    "                'pred': pred,\n",
    "                'loss': loss\n",
    "            })\n",
    "    \n",
    "    if len(month_samples) > 0:\n",
    "        month_df = pd.DataFrame(month_samples)\n",
    "        avg_loss = month_df['loss'].mean()\n",
    "        total_target = month_df['target'].sum()\n",
    "        total_pred = month_df['pred'].sum()\n",
    "        \n",
    "        print(f\"\\n{month_name} 2024:\")\n",
    "        print(f\"  Samples: {len(month_df)}\")\n",
    "        print(f\"  Avg quantile loss: {avg_loss:,.0f}\")\n",
    "        print(f\"  Total actual: {total_target:,.0f} kg\")\n",
    "        print(f\"  Total predicted: {total_pred:,.0f} kg\")\n",
    "        print(f\"  Prediction ratio: {total_pred/total_target:.3f}x\" if total_target > 0 else \"  Prediction ratio: N/A\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Note: This uses simple rate_90 baseline, not full Step 5 model\")\n",
    "print(\"Full Step 5 model would require retraining for each month\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: INACTIVE RMs SANITY CHECK\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SECTION 7: INACTIVE RMs SANITY CHECK\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "inactive_analysis = []\n",
    "\n",
    "for rm_id in inactive_rms:\n",
    "    rm_data = receivals[receivals['rm_id'] == rm_id]\n",
    "    \n",
    "    if len(rm_data) > 0:\n",
    "        last_delivery = rm_data['date_arrival'].max()\n",
    "        \n",
    "        # Total in 365 days before last delivery\n",
    "        year_before_last = rm_data[\n",
    "            (rm_data['date_arrival'] >= last_delivery - timedelta(days=365)) &\n",
    "            (rm_data['date_arrival'] <= last_delivery)\n",
    "        ]\n",
    "        total_last_365 = year_before_last['net_weight'].sum()\n",
    "        \n",
    "    else:\n",
    "        last_delivery = None\n",
    "        total_last_365 = 0\n",
    "    \n",
    "    # Check for 2025 POs\n",
    "    has_2025_po = False\n",
    "    if len(purchase_orders) > 0:\n",
    "        po_2025 = purchase_orders[\n",
    "            (purchase_orders['product_id'].notna()) &\n",
    "            (purchase_orders['delivery_date'].dt.year == 2025)\n",
    "        ]\n",
    "        # This is approximate - would need product→rm mapping\n",
    "        has_2025_po = len(po_2025) > 0\n",
    "    \n",
    "    inactive_analysis.append({\n",
    "        'rm_id': rm_id,\n",
    "        'last_delivery_date': last_delivery,\n",
    "        'days_since_last': (pd.to_datetime('2025-01-01') - last_delivery).days if last_delivery else 99999,\n",
    "        'total_last_365_before_last': total_last_365,\n",
    "        'any_2025_PO_flag': has_2025_po  # Note: crude approximation\n",
    "    })\n",
    "\n",
    "inactive_df = pd.DataFrame(inactive_analysis)\n",
    "\n",
    "print(f\"\\n--- Inactive RMs Summary ({len(inactive_df)} RMs) ---\")\n",
    "print(f\"RMs with no history at all: {inactive_df['last_delivery_date'].isna().sum()}\")\n",
    "print(f\"RMs with last delivery > 1 year ago: {(inactive_df['days_since_last'] > 365).sum()}\")\n",
    "print(f\"RMs with last delivery > 5 years ago: {(inactive_df['days_since_last'] > 1825).sum()}\")\n",
    "print(f\"RMs with last delivery > 10 years ago: {(inactive_df['days_since_last'] > 3650).sum()}\")\n",
    "\n",
    "print(\"\\n--- Days Since Last Delivery Distribution ---\")\n",
    "days_since_stats = inactive_df['days_since_last'].describe()\n",
    "print(days_since_stats)\n",
    "\n",
    "print(\"\\n--- Last Year Activity Before Going Inactive ---\")\n",
    "print(inactive_df['total_last_365_before_last'].describe())\n",
    "\n",
    "print(\"\\n--- Sample of Inactive RMs (sorted by most recent) ---\")\n",
    "sample_inactive = inactive_df.nsmallest(10, 'days_since_last')[\n",
    "    ['rm_id', 'last_delivery_date', 'days_since_last', 'total_last_365_before_last']\n",
    "]\n",
    "print(sample_inactive.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- Recommendation ---\")\n",
    "highly_inactive = (inactive_df['days_since_last'] > 1825).sum()\n",
    "print(f\"RMs inactive > 5 years: {highly_inactive}/{len(inactive_df)} ({highly_inactive/len(inactive_df)*100:.1f}%)\")\n",
    "print(\"These should almost certainly be predicted as 0\")\n",
    "\n",
    "recently_inactive = ((inactive_df['days_since_last'] > 365) & (inactive_df['days_since_last'] <= 730)).sum()\n",
    "print(f\"\\nRMs inactive 1-2 years: {recently_inactive}/{len(inactive_df)} ({recently_inactive/len(inactive_df)*100:.1f}%)\")\n",
    "print(\"These might have small reactivation probability - needs judgment\")\n",
    "\n",
    "inactive_df.to_csv('section7_inactive_rms.csv', index=False)\n",
    "print(\"\\n✅ Saved detailed data to 'section7_inactive_rms.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE EDA COMPLETE - FILES SAVED\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nGenerated CSV files:\")\n",
    "print(\"  1. section1_rm_activity_snapshot.csv\")\n",
    "print(\"  2. section2_renewal_diagnostics.csv\")\n",
    "print(\"  3. section3_guardrail_curves.csv\")\n",
    "print(\"  4. section4_growth_curves.csv\")\n",
    "print(\"  5. section5_mix_stability.csv\")\n",
    "print(\"  6. (Section 6 printed inline)\")\n",
    "print(\"  7. section7_inactive_rms.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY TAKEAWAYS FOR NEW MODELING APPROACH\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. STEADY VS LUMPY RMs:\")\n",
    "print(f\"   - {(activity_df['cv_batch'] <= 1.0).sum()}/{len(activity_df)} RMs are 'steady' (CV < 1.0)\")\n",
    "print(f\"   - {(activity_df['cv_batch'] > 1.0).sum()}/{len(activity_df)} RMs are 'lumpy' (CV > 1.0)\")\n",
    "print(\"   → Consider different models for each category\")\n",
    "\n",
    "print(\"\\n2. RENEWAL PROCESS VIABILITY:\")\n",
    "print(f\"   - {(renewal_df['cv_interarrival_365d'] < 0.5).sum()}/{len(renewal_df)} RMs have regular deliveries\")\n",
    "print(f\"   - {(renewal_df['cv_batch_365d'] < 0.5).sum()}/{len(renewal_df)} RMs have consistent batch sizes\")\n",
    "print(\"   → Renewal/compound Poisson models viable for ~half of RMs\")\n",
    "\n",
    "print(\"\\n3. GUARDRAIL INSIGHTS:\")\n",
    "print(\"   - P(Y>0) drops sharply after 90 days inactive\")\n",
    "print(\"   - But not zero until >365 days\")\n",
    "print(\"   → Current 365-day cutoff is reasonable but could be softened\")\n",
    "\n",
    "print(\"\\n4. GROWTH CURVES:\")\n",
    "print(\"   - Cumulative delivery is concave (sublinear)\")\n",
    "print(\"   - Strong RM-specific patterns exist\")\n",
    "print(\"   → Per-RM growth templates could improve long-horizon predictions\")\n",
    "\n",
    "print(\"\\n5. MIX STABILITY:\")\n",
    "print(f\"   - {(mix_df['supplier_jaccard'] > 0.7).sum()}/{len(mix_df)} RMs have stable supplier mix\")\n",
    "print(f\"   - {(mix_df['product_jaccard'] > 0.7).sum()}/{len(mix_df)} RMs have stable product mix\")\n",
    "print(\"   → Can use supplier/product lags for stable RMs only\")\n",
    "\n",
    "print(\"\\n6. INACTIVE RMs:\")\n",
    "print(f\"   - {highly_inactive}/{len(inactive_df)} inactive > 5 years (should be 0)\")\n",
    "print(f\"   - {recently_inactive}/{len(inactive_df)} inactive 1-2 years (edge cases)\")\n",
    "print(\"   → Zero-prediction policy is correct for vast majority\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
